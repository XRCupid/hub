{"version":3,"file":"static/js/770.c429e0fd.chunk.js","mappings":"sNAsDO,MAAMA,EAA8DC,IAapE,IAbqE,UAC1EC,EAAS,aACTC,EAAY,SACZC,EAAW,CAAC,GAAI,GAAK,GAAE,SACvBC,EAAW,CAAC,EAAG,EAAG,GAAE,MACpBC,EAAQ,CAAC,IAAK,IAAK,KAAI,qBACvBC,GAAuB,EAAK,aAC5BC,EAAe,CAAEC,MAAO,EAAGC,IAAK,EAAGC,KAAM,GAAG,YAC5CC,EAAc,CAAC,EAAC,QAChBC,EAAU,CAAC,EAAC,WACZC,GAAa,EAAK,eAClBC,EAAiB,EAAC,eAClBC,EAAiB,WAClBf,EACC,MAAM,MAAEgB,IAAUC,EAAAA,EAAAA,GAAQhB,GACpBiB,GAAgBD,EAAAA,EAAAA,GAAQf,GAAgBD,GACxCkB,EAAYjB,EAAegB,EAAcE,WAAa,IACtD,QAAEC,IAAYC,EAAAA,EAAAA,GAAcH,EAAWH,GAEvCO,GAAWC,EAAAA,EAAAA,QAA0B,MACrCC,GAAWD,EAAAA,EAAAA,QAA0B,MACrCE,GAAeF,EAAAA,EAAAA,QAAsC,CAAC,GAGtDG,EACM,CAAEnB,MAAO,EAAGC,IAAK,EAAGC,KAAM,GADhCiB,GAEY,EAFZA,EAGG,KAyKT,OAnKAC,EAAAA,EAAAA,YAAU,KACJtB,IACFuB,QAAQC,IAAI,2BAA4BH,GACpCA,GACFE,QAAQE,MAAM,gBAAiBJ,MAGlC,CAACrB,EAAsBqB,EAA+BA,KAGzDC,EAAAA,EAAAA,YAAU,KACJZ,GACFA,EAAMgB,UAAUC,IACd,GAAIA,aAAiBC,EAAAA,KAAY,CAC/B,MAAMC,EAAWF,EAAMG,KAAKC,cACxBF,EAASG,SAAS,QAASf,EAASgB,QAAUN,EACzCE,EAASG,SAAS,UAASb,EAASc,QAAUN,EACzD,CAEIA,aAAiBC,EAAAA,aAAqBD,EAAMO,wBAC9Cd,EAAaa,QAAQN,EAAMG,MAAQH,QAIxC,CAACjB,KAGJY,EAAAA,EAAAA,YAAU,KAER,GAAIP,GAAWF,EAAUsB,OAAS,EAAG,CAAC,IAADC,EAEnC,MAIMC,EAJWxB,EAAUyB,MAAKC,GAC9BA,EAAKT,KAAKC,cAAcC,SAAS,SACjCO,EAAKT,KAAKC,cAAcC,SAAS,eAEJnB,EAAU,GACjB,QAAxBuB,EAAArB,EAAQsB,EAAWP,aAAK,IAAAM,GAAxBA,EAA0BI,QAAQC,OAAO,IAAKC,MAChD,CACA,MAAO,KACLC,OAAOC,OAAO7B,GAAS8B,SAASC,GAAiB,OAANA,QAAM,IAANA,OAAM,EAANA,EAAQC,YAEpD,CAAChC,EAASF,KAGbmC,EAAAA,EAAAA,IAAUC,IACR,MAAMC,EAAOD,EAAME,MAAMC,iBAGzB,IAAIC,GAAaC,EAAAA,EAAAA,GAAA,GAAQrD,GAQzB,GAPID,IACFqD,EAAcnD,OAASmB,EAAwBnB,MAC/CmD,EAAclD,KAAOkB,EAAwBlB,IAC7CkD,EAAcjD,MAAQiB,EAAwBjB,MAI5Ca,EAASgB,QAAS,CAepB,OAbAhB,EAASgB,QAAQnC,SAASyD,EAAI,GAC9BtC,EAASgB,QAAQnC,SAAS0D,EAAI5B,EAAAA,UAAgB6B,KAC5CxC,EAASgB,QAAQnC,SAAS0D,EACN,GAApBH,EAAclD,IACd,IAEFc,EAASgB,QAAQnC,SAAS4D,EAAI9B,EAAAA,UAAgB6B,KAC5CxC,EAASgB,QAAQnC,SAAS4D,EACL,GAArBL,EAAcjD,KACd,IAIKK,GACL,IAAK,QACHQ,EAASgB,QAAQnC,SAAS0D,GAA0B,IAArBG,KAAKC,IAAW,EAAPV,GACxC,MACF,IAAK,MACHjC,EAASgB,QAAQnC,SAAS0D,GAAK,GAC/B,MACF,IAAK,UACHvC,EAASgB,QAAQnC,SAAS4D,GAA0B,IAArBC,KAAKC,IAAW,EAAPV,GACxC,MACF,IAAK,aACHjC,EAASgB,QAAQnC,SAASyD,GAA4B,IAAvBI,KAAKC,IAAW,GAAPV,GACxC,MACF,IAAK,QACHjC,EAASgB,QAAQnC,SAAS0D,GAAK,IAC/B,MACF,IAAK,YACHvC,EAASgB,QAAQnC,SAAS0D,GAAK,IAK/BjD,IACFU,EAASgB,QAAQnC,SAAS0D,GAAKG,KAAKC,IAAW,EAAPV,GAAY1C,EAAiB,IAEzE,CAGIW,EAASc,UACXd,EAASc,QAAQnC,SAASyD,EAA0B,GAAtBF,EAAcnD,MAC5CiB,EAASc,QAAQnC,SAAS0D,EAAwB,GAApBH,EAAclD,KAI9CwC,OAAOkB,QAAQzC,EAAaa,SAASY,SAAQiB,IAAuB,IAArBC,EAAUC,GAAKF,EAC5D,IAAKE,EAAK9B,wBAA0B8B,EAAKC,sBAAuB,OAGhEtB,OAAOkB,QAAQxD,GAAawC,SAAQqB,IAA0B,IAAxBC,EAAYC,GAAMF,EACtD,GAAIF,EAAK9B,uBAAyB8B,EAAKC,sBAAuB,CAC5D,MAAMI,EAAaL,EAAK9B,sBAAsBiC,QAC3BG,IAAfD,IACFL,EAAKC,sBAAsBI,GAAcD,GAAS,EAEtD,KAIFzB,OAAOkB,QAAQvD,GAASuC,SAAQ0B,IAAsB,IAApBC,EAAQJ,GAAMG,EAC9C,GAAIP,EAAK9B,uBAAyB8B,EAAKC,sBAAuB,CAC5D,MAAMI,EAAaL,EAAK9B,sBAAsB,UAADuC,OAAWD,SACrCF,IAAfD,IACFL,EAAKC,sBAAsBI,GAAcD,GAAS,EAEtD,KAIF,MAAMM,EAAmE,CACvEC,MAAO,CAAEC,WAAY,GAAKC,cAAe,GAAKC,eAAgB,IAC9DC,IAAK,CAAEC,eAAgB,GAAKC,gBAAiB,GAAKC,WAAY,IAC9DC,MAAO,CAAEC,aAAc,GAAKC,cAAe,GAAKL,eAAgB,GAAKC,gBAAiB,IACtFK,UAAW,CAAEC,YAAa,GAAKC,aAAc,GAAKC,UAAW,GAAKC,YAAa,IAC/EC,WAAY,CAAEP,aAAc,GAAKC,cAAe,GAAKO,YAAa,KAiBpE,GAdIlB,EAAmBjE,IAAmBuD,EAAK9B,uBAAyB8B,EAAKC,uBAC3EtB,OAAOkB,QAAQa,EAAmBjE,IAAiBoC,SAAQgD,IAAyB,IAAvBC,EAAW1B,GAAMyB,EAC5E,MAAMxB,EAAaL,EAAK9B,sBAAuB4D,QAC5BxB,IAAfD,IAEFL,EAAKC,sBAAuBI,GAAcV,KAAKoC,IAC7C/B,EAAKC,sBAAuBI,GAC5BD,OAOJJ,EAAK9B,uBAAyB8B,EAAKC,sBAAuB,CAC5D,MACM+B,EAAgB,EAChBC,EAAQtC,KAAKC,IAAIV,EAAO8C,GAAiB,IAAO,EAAI,EACpDE,EAAYlC,EAAK9B,sBAAoC,aACrDiE,EAAanC,EAAK9B,sBAAqC,mBAC3CoC,IAAd4B,IAAyBlC,EAAKC,sBAAsBiC,GAAaD,QAClD3B,IAAf6B,IAA0BnC,EAAKC,sBAAsBkC,GAAcF,EACzE,QAICvF,GAGH0F,EAAAA,EAAAA,KAAA,SACEvG,SAAUA,EACVE,MAAOA,EACPD,SAAU,CAAC,IAAM,EAAG,GAAIuG,UAExBD,EAAAA,EAAAA,KAAA,aACEE,OAAQ5F,MATK,K","sources":["components/RPMAvatarWithTracking.tsx"],"sourcesContent":["import React, { useEffect, useRef, useState } from 'react';\nimport { useGLTF, useAnimations } from '@react-three/drei';\nimport { useFrame } from '@react-three/fiber';\nimport * as THREE from 'three';\n// Temporarily disabled to prevent console errors\n// import { useWebcamTracking } from '../hooks/useWebcamTracking';\n\ninterface RPMAvatarWithTrackingProps {\n  avatarUrl: string;\n  animationUrl?: string;\n  position?: [number, number, number];\n  rotation?: [number, number, number];\n  scale?: [number, number, number];\n  \n  // Head tracking\n  enableWebcamTracking?: boolean;\n  headRotation?: { pitch: number; yaw: number; roll: number };\n  \n  // Facial expressions (0-1 values)\n  expressions?: {\n    happy?: number;\n    sad?: number;\n    angry?: number;\n    surprised?: number;\n    disgusted?: number;\n    fearful?: number;\n  };\n  \n  // Visemes for lip sync (0-1 values)\n  visemes?: {\n    aa?: number;\n    E?: number;\n    I?: number;\n    O?: number;\n    U?: number;\n    CH?: number;\n    DD?: number;\n    FF?: number;\n    kk?: number;\n    nn?: number;\n    PP?: number;\n    RR?: number;\n    SS?: number;\n    TH?: number;\n  };\n  \n  // Voice data\n  isSpeaking?: boolean;\n  voiceIntensity?: number;\n  \n  // Emotion from voice/context\n  emotionalState?: 'neutral' | 'happy' | 'sad' | 'excited' | 'thoughtful' | 'angry' | 'surprised';\n}\n\nexport const RPMAvatarWithTracking: React.FC<RPMAvatarWithTrackingProps> = ({\n  avatarUrl,\n  animationUrl,\n  position = [0, -0.4, 0], // Raise slightly to center face\n  rotation = [0, 0, 0], // Natural pose\n  scale = [1.2, 1.2, 1.2], // Slightly larger for close-up\n  enableWebcamTracking = false,\n  headRotation = { pitch: 0, yaw: 0, roll: 0 },\n  expressions = {},\n  visemes = {},\n  isSpeaking = false,\n  voiceIntensity = 0,\n  emotionalState = 'neutral',\n}) => {\n  const { scene } = useGLTF(avatarUrl);\n  const animationGltf = useGLTF(animationUrl || avatarUrl); // Always call the hook\n  const animClips = animationUrl ? animationGltf.animations : [];\n  const { actions } = useAnimations(animClips, scene);\n  \n  const headBone = useRef<THREE.Bone | null>(null);\n  const neckBone = useRef<THREE.Bone | null>(null);\n  const morphTargets = useRef<{ [key: string]: THREE.Mesh }>({});\n  \n  // Temporarily disable webcam tracking to prevent errors\n  const webcamTracking = {\n    rotation: { pitch: 0, yaw: 0, roll: 0 },\n    isWebcamActive: false,\n    error: null,\n    startWebcam: () => {},\n    stopWebcam: () => {}\n  };\n  \n  // Log webcam status\n  useEffect(() => {\n    if (enableWebcamTracking) {\n      console.log('Webcam tracking enabled:', webcamTracking.isWebcamActive);\n      if (webcamTracking.error) {\n        console.error('Webcam error:', webcamTracking.error);\n      }\n    }\n  }, [enableWebcamTracking, webcamTracking.isWebcamActive, webcamTracking.error]);\n  \n  // Find bones and morph targets\n  useEffect(() => {\n    if (scene) {\n      scene.traverse((child) => {\n        if (child instanceof THREE.Bone) {\n          const boneName = child.name.toLowerCase();\n          if (boneName.includes('head')) headBone.current = child;\n          else if (boneName.includes('neck')) neckBone.current = child;\n        }\n        \n        if (child instanceof THREE.SkinnedMesh && child.morphTargetDictionary) {\n          morphTargets.current[child.name] = child;\n        }\n      });\n    }\n  }, [scene]);\n  \n  // Play animations\n  useEffect(() => {\n    // Try different animation - use idle.glb instead of M_Standing_Idle_001.glb\n    if (actions && animClips.length > 0) {\n      // Find the best animation clip\n      const idleClip = animClips.find(clip => \n        clip.name.toLowerCase().includes('idle') || \n        clip.name.toLowerCase().includes('standing')\n      );\n      const clipToPlay = idleClip || animClips[0];\n      actions[clipToPlay.name]?.reset().fadeIn(0.2).play();\n    }\n    return () => {\n      Object.values(actions).forEach((action) => action?.stop());\n    };\n  }, [actions, animClips]);\n  \n  // Apply all transformations\n  useFrame((state) => {\n    const time = state.clock.getElapsedTime();\n    \n    // Combine head rotations\n    let finalRotation = { ...headRotation };\n    if (enableWebcamTracking) {\n      finalRotation.pitch += webcamTracking.rotation.pitch;\n      finalRotation.yaw += webcamTracking.rotation.yaw;\n      finalRotation.roll += webcamTracking.rotation.roll;\n    }\n    \n    // Apply head rotation\n    if (headBone.current) {\n      // Base forward tilt to prevent backward lean\n      headBone.current.rotation.x = 0.3; // Forward tilt for T-pose\n      headBone.current.rotation.y = THREE.MathUtils.lerp(\n        headBone.current.rotation.y,\n        finalRotation.yaw * 0.7,\n        0.1\n      );\n      headBone.current.rotation.z = THREE.MathUtils.lerp(\n        headBone.current.rotation.z,\n        finalRotation.roll * 0.3,\n        0.1\n      );\n      \n      // Add subtle movements based on emotional state\n      switch(emotionalState) {\n        case 'happy':\n          headBone.current.rotation.y += Math.sin(time * 2) * 0.02;\n          break;\n        case 'sad':\n          headBone.current.rotation.y -= 0.1;\n          break;\n        case 'excited':\n          headBone.current.rotation.z += Math.sin(time * 4) * 0.03;\n          break;\n        case 'thoughtful':\n          headBone.current.rotation.x += Math.sin(time * 0.5) * 0.02;\n          break;\n        case 'angry':\n          headBone.current.rotation.y -= 0.05;\n          break;\n        case 'surprised':\n          headBone.current.rotation.y += 0.05;\n          break;\n      }\n      \n      // Add speaking motion\n      if (isSpeaking) {\n        headBone.current.rotation.y += Math.sin(time * 8) * voiceIntensity * 0.03;\n      }\n    }\n    \n    // Apply neck rotation (softer)\n    if (neckBone.current) {\n      neckBone.current.rotation.x = finalRotation.pitch * 0.3;\n      neckBone.current.rotation.y = finalRotation.yaw * 0.3;\n    }\n    \n    // Apply facial expressions and visemes\n    Object.entries(morphTargets.current).forEach(([meshName, mesh]) => {\n      if (!mesh.morphTargetDictionary || !mesh.morphTargetInfluences) return;\n      \n      // Apply expressions\n      Object.entries(expressions).forEach(([expression, value]) => {\n        if (mesh.morphTargetDictionary && mesh.morphTargetInfluences) {\n          const morphIndex = mesh.morphTargetDictionary[expression];\n          if (morphIndex !== undefined) {\n            mesh.morphTargetInfluences[morphIndex] = value || 0;\n          }\n        }\n      });\n      \n      // Apply visemes (mouth shapes for speech)\n      Object.entries(visemes).forEach(([viseme, value]) => {\n        if (mesh.morphTargetDictionary && mesh.morphTargetInfluences) {\n          const morphIndex = mesh.morphTargetDictionary[`viseme_${viseme}`];\n          if (morphIndex !== undefined) {\n            mesh.morphTargetInfluences[morphIndex] = value || 0;\n          }\n        }\n      });\n      \n      // Apply emotion-based expressions\n      const emotionExpressions: { [key: string]: { [key: string]: number } } = {\n        happy: { mouthSmile: 0.7, eyeSquintLeft: 0.3, eyeSquintRight: 0.3 },\n        sad: { mouthFrownLeft: 0.5, mouthFrownRight: 0.5, eyesClosed: 0.2 },\n        angry: { browDownLeft: 0.8, browDownRight: 0.8, mouthFrownLeft: 0.3, mouthFrownRight: 0.3 },\n        surprised: { eyeWideLeft: 0.8, eyeWideRight: 0.8, mouthOpen: 0.5, browInnerUp: 0.7 },\n        thoughtful: { browDownLeft: 0.2, browDownRight: 0.2, mouthPucker: 0.2 },\n      };\n      \n      if (emotionExpressions[emotionalState] && mesh.morphTargetDictionary && mesh.morphTargetInfluences) {\n        Object.entries(emotionExpressions[emotionalState]).forEach(([morphName, value]) => {\n          const morphIndex = mesh.morphTargetDictionary![morphName];\n          if (morphIndex !== undefined) {\n            // Blend with existing value\n            mesh.morphTargetInfluences![morphIndex] = Math.max(\n              mesh.morphTargetInfluences![morphIndex],\n              value\n            );\n          }\n        });\n      }\n      \n      // Natural blinking\n      if (mesh.morphTargetDictionary && mesh.morphTargetInfluences) {\n        const blinkSpeed = 0.15;\n        const blinkInterval = 4;\n        const blink = Math.sin(time * blinkInterval) > 0.95 ? 1 : 0;\n        const blinkLeft = mesh.morphTargetDictionary['eyeBlinkLeft'];\n        const blinkRight = mesh.morphTargetDictionary['eyeBlinkRight'];\n        if (blinkLeft !== undefined) mesh.morphTargetInfluences[blinkLeft] = blink;\n        if (blinkRight !== undefined) mesh.morphTargetInfluences[blinkRight] = blink;\n      }\n    });\n  });\n  \n  if (!scene) return null;\n  \n  return (\n    <group \n      position={position} \n      scale={scale}\n      rotation={[0.05, 0, 0]} // Very subtle forward tilt\n    >\n      <primitive \n        object={scene} \n      />\n    </group>\n  );\n}\n"],"names":["RPMAvatarWithTracking","_ref","avatarUrl","animationUrl","position","rotation","scale","enableWebcamTracking","headRotation","pitch","yaw","roll","expressions","visemes","isSpeaking","voiceIntensity","emotionalState","scene","useGLTF","animationGltf","animClips","animations","actions","useAnimations","headBone","useRef","neckBone","morphTargets","webcamTracking","useEffect","console","log","error","traverse","child","THREE","boneName","name","toLowerCase","includes","current","morphTargetDictionary","length","_actions$clipToPlay$n","clipToPlay","find","clip","reset","fadeIn","play","Object","values","forEach","action","stop","useFrame","state","time","clock","getElapsedTime","finalRotation","_objectSpread","x","y","lerp","z","Math","sin","entries","_ref2","meshName","mesh","morphTargetInfluences","_ref3","expression","value","morphIndex","undefined","_ref4","viseme","concat","emotionExpressions","happy","mouthSmile","eyeSquintLeft","eyeSquintRight","sad","mouthFrownLeft","mouthFrownRight","eyesClosed","angry","browDownLeft","browDownRight","surprised","eyeWideLeft","eyeWideRight","mouthOpen","browInnerUp","thoughtful","mouthPucker","_ref5","morphName","max","blinkInterval","blink","blinkLeft","blinkRight","_jsx","children","object"],"sourceRoot":""}