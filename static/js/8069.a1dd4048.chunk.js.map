{"version":3,"file":"static/js/8069.a1dd4048.chunk.js","mappings":"kKAOO,MAAMA,EAAgEC,IAGtE,IAHuE,kBAC5EC,EAAiB,UACjBC,GAAY,GACbF,EACC,MAAOG,EAAWC,IAAgBC,EAAAA,EAAAA,WAAS,IACpCC,EAAiBC,IAAsBF,EAAAA,EAAAA,UAAS,GACjDG,GAAWC,EAAAA,EAAAA,QAAyB,MACpCC,GAAYD,EAAAA,EAAAA,QAA0B,MACtCE,GAAcF,EAAAA,EAAAA,UACdG,GAAoBH,EAAAA,EAAAA,QAAkB,IAoG5C,OAlGAI,EAAAA,EAAAA,YAAU,KACR,IAAIC,EAA6B,KAuFjC,MArFsBC,WACpB,IAEED,QAAeE,UAAUC,aAAaC,aAAa,CACjDC,MAAO,CACLC,MAAO,IACPC,OAAQ,IACRC,WAAY,UAIZd,EAASe,UACXf,EAASe,QAAQC,UAAYV,GAI/BH,EAAYY,QAAUE,OAAOC,aAAY,KACvC,GAAIlB,EAASe,SAAWb,EAAUa,QAAS,CACzC,MAAMJ,EAAQX,EAASe,QACjBI,EAASjB,EAAUa,QACnBK,EAAMD,EAAOE,WAAW,MAE9B,IAAKD,EAAK,OAEVD,EAAOP,MAAQ,IACfO,EAAON,OAAS,IAChBO,EAAIE,UAAUX,EAAO,EAAG,EAAGQ,EAAOP,MAAOO,EAAON,QAGhD,MACMU,EADYH,EAAII,aAAa,EAAG,EAAGL,EAAOP,MAAOO,EAAON,QACvCU,KAGvB,IAAIE,EAAa,EACjB,MAAMC,EAAUP,EAAOP,MAAQ,EACzBe,EAAUR,EAAON,OAAS,EAC1Be,EAAc,GAEpB,IAAK,IAAIC,EAAIF,EAAUC,EAAaC,EAAIF,EAAUC,EAAaC,IAC7D,IAAK,IAAIC,EAAIJ,EAAUE,EAAaE,EAAIJ,EAAUE,EAAaE,IAAK,CAClE,MAAMC,EAA+B,GAAxBF,EAAIV,EAAOP,MAAQkB,GAC1BE,EAAIT,EAAKQ,GACTE,EAAIV,EAAKQ,EAAM,GACfG,EAAIX,EAAKQ,EAAM,GAGjBC,EAAI,IAAMC,EAAI,IAAMC,EAAI,IACxBF,EAAIC,GAAKD,EAAIE,GACbC,KAAKC,IAAIJ,EAAIC,GAAK,IACpBR,GAEJ,CAIF,MAEMY,EADYZ,GADEG,EAAcA,EAAc,GAEpB,IAE5BhC,EAAayC,GACbjC,EAAkBW,QAAQuB,KAAKD,GAG3BjC,EAAkBW,QAAQwB,OAAS,IACrCnC,EAAkBW,QAAQyB,QAI5B,MAAMC,EAAerC,EAAkBW,QAAQ2B,QAAOC,GAAKA,IAAGJ,OACxDK,EAAQT,KAAKU,MAAOJ,EAAerC,EAAkBW,QAAQwB,OAAU,KAC7ExC,EAAmB6C,GAEfnD,GACFA,EAAkB4C,EAEtB,IACC,IAEL,CAAE,MAAOS,GACPC,QAAQD,MAAM,sCAAuCA,EACvD,GAGFE,GAEO,KACD7C,EAAYY,SACdkC,cAAc9C,EAAYY,SAExBT,GACFA,EAAO4C,YAAYC,SAAQC,GAASA,EAAMC,YAG7C,CAAC5D,KAGF6D,EAAAA,EAAAA,MAAA,OAAKC,MAAO,CACVC,QAAS,OACTC,gBAAiB,qBACjBC,aAAc,MACdC,MAAO,SACPC,SAAA,EACAC,EAAAA,EAAAA,KAAA,MAAAD,SAAI,uBAEJN,EAAAA,EAAAA,MAAA,OAAKC,MAAO,CAAEO,QAAS,OAAQC,IAAK,OAAQC,WAAY,UAAWJ,SAAA,EACjEN,EAAAA,EAAAA,MAAA,OAAKC,MAAO,CAAEU,SAAU,YAAaL,SAAA,EACnCC,EAAAA,EAAAA,KAAA,SACEK,IAAKlE,EACLmE,UAAQ,EACRC,aAAW,EACXC,OAAK,EACLd,MAAO,CACL3C,MAAO,QACPC,OAAQ,QACRiD,QAASpE,EAAY,QAAU,OAC/BgE,aAAc,UAGlBG,EAAAA,EAAAA,KAAA,UACEK,IAAKhE,EACLqD,MAAO,CAAEO,QAAS,cAItBR,EAAAA,EAAAA,MAAA,OAAAM,SAAA,EACEC,EAAAA,EAAAA,KAAA,OAAKN,MAAO,CACVe,SAAU,OACVC,aAAc,OACdZ,MAAOhE,EAAY,UAAY,WAC/BiE,SACCjE,EAAY,uBAAe,8BAG9B2D,EAAAA,EAAAA,MAAA,OAAAM,SAAA,EACEN,EAAAA,EAAAA,MAAA,OAAKC,MAAO,CAAEgB,aAAc,OAAQX,SAAA,CAAC,eAAa9D,EAAgB,QAClE+D,EAAAA,EAAAA,KAAA,OAAKN,MAAO,CACV3C,MAAO,QACPC,OAAQ,OACR4C,gBAAiB,OACjBC,aAAc,OACdc,SAAU,UACVZ,UACAC,EAAAA,EAAAA,KAAA,OAAKN,MAAO,CACV3C,MAAM,GAAD6D,OAAK3E,EAAe,KACzBe,OAAQ,OACR4C,gBAAiB3D,EAAkB,GAAK,UAAYA,EAAkB,GAAK,UAAY,UACvF4E,WAAY,mC","sources":["components/SimpleAttentionTracker.tsx"],"sourcesContent":["import React, { useEffect, useState, useRef } from 'react';\n\ninterface SimpleAttentionTrackerProps {\n  onAttentionChange?: (isLooking: boolean) => void;\n  showVideo?: boolean;\n}\n\nexport const SimpleAttentionTracker: React.FC<SimpleAttentionTrackerProps> = ({\n  onAttentionChange,\n  showVideo = true\n}) => {\n  const [isLooking, setIsLooking] = useState(false);\n  const [engagementScore, setEngagementScore] = useState(0);\n  const videoRef = useRef<HTMLVideoElement>(null);\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const intervalRef = useRef<number>();\n  const lookingHistoryRef = useRef<boolean[]>([]);\n\n  useEffect(() => {\n    let stream: MediaStream | null = null;\n\n    const startTracking = async () => {\n      try {\n        // Get camera stream\n        stream = await navigator.mediaDevices.getUserMedia({ \n          video: { \n            width: 320, \n            height: 240,\n            facingMode: 'user'\n          } \n        });\n\n        if (videoRef.current) {\n          videoRef.current.srcObject = stream;\n        }\n\n        // Simple face detection using basic image analysis\n        intervalRef.current = window.setInterval(() => {\n          if (videoRef.current && canvasRef.current) {\n            const video = videoRef.current;\n            const canvas = canvasRef.current;\n            const ctx = canvas.getContext('2d');\n            \n            if (!ctx) return;\n\n            canvas.width = 320;\n            canvas.height = 240;\n            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);\n            \n            // Get image data for simple analysis\n            const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);\n            const data = imageData.data;\n            \n            // Simple heuristic: check center region for face-like colors\n            let facePixels = 0;\n            const centerX = canvas.width / 2;\n            const centerY = canvas.height / 2;\n            const checkRadius = 60;\n            \n            for (let y = centerY - checkRadius; y < centerY + checkRadius; y++) {\n              for (let x = centerX - checkRadius; x < centerX + checkRadius; x++) {\n                const idx = (y * canvas.width + x) * 4;\n                const r = data[idx];\n                const g = data[idx + 1];\n                const b = data[idx + 2];\n                \n                // Check for skin-tone colors (very basic)\n                if (r > 95 && g > 40 && b > 20 && \n                    r > g && r > b && \n                    Math.abs(r - g) > 15) {\n                  facePixels++;\n                }\n              }\n            }\n            \n            // If enough face pixels detected, assume looking\n            const totalPixels = checkRadius * checkRadius * 4;\n            const faceRatio = facePixels / totalPixels;\n            const looking = faceRatio > 0.15; // 15% threshold\n            \n            setIsLooking(looking);\n            lookingHistoryRef.current.push(looking);\n            \n            // Keep last 30 samples (about 10 seconds at 3fps)\n            if (lookingHistoryRef.current.length > 30) {\n              lookingHistoryRef.current.shift();\n            }\n            \n            // Calculate engagement score\n            const lookingCount = lookingHistoryRef.current.filter(l => l).length;\n            const score = Math.round((lookingCount / lookingHistoryRef.current.length) * 100);\n            setEngagementScore(score);\n            \n            if (onAttentionChange) {\n              onAttentionChange(looking);\n            }\n          }\n        }, 333); // ~3 FPS\n\n      } catch (error) {\n        console.error('Failed to start attention tracking:', error);\n      }\n    };\n\n    startTracking();\n\n    return () => {\n      if (intervalRef.current) {\n        clearInterval(intervalRef.current);\n      }\n      if (stream) {\n        stream.getTracks().forEach(track => track.stop());\n      }\n    };\n  }, [onAttentionChange]);\n\n  return (\n    <div style={{ \n      padding: '20px',\n      backgroundColor: 'rgba(0, 0, 0, 0.8)',\n      borderRadius: '8px',\n      color: 'white'\n    }}>\n      <h3>Attention Tracker</h3>\n      \n      <div style={{ display: 'flex', gap: '20px', alignItems: 'center' }}>\n        <div style={{ position: 'relative' }}>\n          <video\n            ref={videoRef}\n            autoPlay\n            playsInline\n            muted\n            style={{\n              width: '160px',\n              height: '120px',\n              display: showVideo ? 'block' : 'none',\n              borderRadius: '4px'\n            }}\n          />\n          <canvas\n            ref={canvasRef}\n            style={{ display: 'none' }}\n          />\n        </div>\n        \n        <div>\n          <div style={{\n            fontSize: '24px',\n            marginBottom: '10px',\n            color: isLooking ? '#4CAF50' : '#f44336'\n          }}>\n            {isLooking ? 'ðŸ‘€ Looking' : 'ðŸ˜´ Not Looking'}\n          </div>\n          \n          <div>\n            <div style={{ marginBottom: '5px' }}>Engagement: {engagementScore}%</div>\n            <div style={{\n              width: '200px',\n              height: '20px',\n              backgroundColor: '#333',\n              borderRadius: '10px',\n              overflow: 'hidden'\n            }}>\n              <div style={{\n                width: `${engagementScore}%`,\n                height: '100%',\n                backgroundColor: engagementScore > 70 ? '#4CAF50' : engagementScore > 40 ? '#ff9800' : '#f44336',\n                transition: 'width 0.3s ease'\n              }} />\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n};\n"],"names":["SimpleAttentionTracker","_ref","onAttentionChange","showVideo","isLooking","setIsLooking","useState","engagementScore","setEngagementScore","videoRef","useRef","canvasRef","intervalRef","lookingHistoryRef","useEffect","stream","async","navigator","mediaDevices","getUserMedia","video","width","height","facingMode","current","srcObject","window","setInterval","canvas","ctx","getContext","drawImage","data","getImageData","facePixels","centerX","centerY","checkRadius","y","x","idx","r","g","b","Math","abs","looking","push","length","shift","lookingCount","filter","l","score","round","error","console","startTracking","clearInterval","getTracks","forEach","track","stop","_jsxs","style","padding","backgroundColor","borderRadius","color","children","_jsx","display","gap","alignItems","position","ref","autoPlay","playsInline","muted","fontSize","marginBottom","overflow","concat","transition"],"sourceRoot":""}