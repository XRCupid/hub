{"version":3,"file":"static/js/3807.5c253d8f.chunk.js","mappings":"2NAsDO,MAAMA,EAA8DC,IAapE,IAbqE,UAC1EC,EAAS,aACTC,EAAY,SACZC,EAAW,CAAC,GAAI,GAAK,GAAE,SACvBC,EAAW,CAAC,EAAG,EAAG,GAAE,MACpBC,EAAQ,CAAC,IAAK,IAAK,KAAI,qBACvBC,GAAuB,EAAK,aAC5BC,EAAe,CAAEC,MAAO,EAAGC,IAAK,EAAGC,KAAM,GAAG,YAC5CC,EAAc,CAAC,EAAC,QAChBC,EAAU,CAAC,EAAC,WACZC,GAAa,EAAK,eAClBC,EAAiB,EAAC,eAClBC,EAAiB,WAClBf,EACC,MAAM,MAAEgB,IAAUC,EAAAA,EAAAA,GAAQhB,GACpBiB,GAAgBD,EAAAA,EAAAA,GAAQf,GAAgBD,GACxCkB,EAAYjB,EAAegB,EAAcE,WAAa,IACtD,QAAEC,IAAYC,EAAAA,EAAAA,GAAcH,EAAWH,GAEvCO,GAAWC,EAAAA,EAAAA,QAA0B,MACrCC,GAAWD,EAAAA,EAAAA,QAA0B,MACrCE,GAAeF,EAAAA,EAAAA,QAAsC,CAAC,GAGtDG,EACM,CAAEnB,MAAO,EAAGC,IAAK,EAAGC,KAAM,GADhCiB,GAEY,EAFZA,EAGG,KAyKT,OAnKAC,EAAAA,EAAAA,YAAU,KACJtB,IACFuB,QAAQC,IAAI,2BAA4BH,GACpCA,GACFE,QAAQE,MAAM,gBAAiBJ,MAGlC,CAACrB,EAAsBqB,EAA+BA,KAGzDC,EAAAA,EAAAA,YAAU,KACJZ,GACFA,EAAMgB,UAAUC,IACd,GAAIA,aAAiBC,EAAAA,KAAY,CAC/B,MAAMC,EAAWF,EAAMG,KAAKC,cACxBF,EAASG,SAAS,QAASf,EAASgB,QAAUN,EACzCE,EAASG,SAAS,UAASb,EAASc,QAAUN,EACzD,CAEIA,aAAiBC,EAAAA,aAAqBD,EAAMO,wBAC9Cd,EAAaa,QAAQN,EAAMG,MAAQH,QAIxC,CAACjB,KAGJY,EAAAA,EAAAA,YAAU,KAER,GAAIP,GAAWF,EAAUsB,OAAS,EAAG,CAAC,IAADC,EAEnC,MAIMC,EAJWxB,EAAUyB,MAAKC,GAC9BA,EAAKT,KAAKC,cAAcC,SAAS,SACjCO,EAAKT,KAAKC,cAAcC,SAAS,eAEJnB,EAAU,GACjB,QAAxBuB,EAAArB,EAAQsB,EAAWP,aAAK,IAAAM,GAAxBA,EAA0BI,QAAQC,OAAO,IAAKC,MAChD,CACA,MAAO,KACLC,OAAOC,OAAO7B,GAAS8B,SAASC,GAAiB,OAANA,QAAM,IAANA,OAAM,EAANA,EAAQC,YAEpD,CAAChC,EAASF,KAGbmC,EAAAA,EAAAA,IAAUC,IACR,MAAMC,EAAOD,EAAME,MAAMC,iBAGzB,IAAIC,GAAaC,EAAAA,EAAAA,GAAA,GAAQrD,GAQzB,GAPID,IACFqD,EAAcnD,OAASmB,EAAwBnB,MAC/CmD,EAAclD,KAAOkB,EAAwBlB,IAC7CkD,EAAcjD,MAAQiB,EAAwBjB,MAI5Ca,EAASgB,QAAS,CAepB,OAbAhB,EAASgB,QAAQnC,SAASyD,EAAI,GAC9BtC,EAASgB,QAAQnC,SAAS0D,EAAI5B,EAAAA,UAAgB6B,KAC5CxC,EAASgB,QAAQnC,SAAS0D,EACN,GAApBH,EAAclD,IACd,IAEFc,EAASgB,QAAQnC,SAAS4D,EAAI9B,EAAAA,UAAgB6B,KAC5CxC,EAASgB,QAAQnC,SAAS4D,EACL,GAArBL,EAAcjD,KACd,IAIKK,GACL,IAAK,QACHQ,EAASgB,QAAQnC,SAAS0D,GAA0B,IAArBG,KAAKC,IAAW,EAAPV,GACxC,MACF,IAAK,MACHjC,EAASgB,QAAQnC,SAAS0D,GAAK,GAC/B,MACF,IAAK,UACHvC,EAASgB,QAAQnC,SAAS4D,GAA0B,IAArBC,KAAKC,IAAW,EAAPV,GACxC,MACF,IAAK,aACHjC,EAASgB,QAAQnC,SAASyD,GAA4B,IAAvBI,KAAKC,IAAW,GAAPV,GACxC,MACF,IAAK,QACHjC,EAASgB,QAAQnC,SAAS0D,GAAK,IAC/B,MACF,IAAK,YACHvC,EAASgB,QAAQnC,SAAS0D,GAAK,IAK/BjD,IACFU,EAASgB,QAAQnC,SAAS0D,GAAKG,KAAKC,IAAW,EAAPV,GAAY1C,EAAiB,IAEzE,CAGIW,EAASc,UACXd,EAASc,QAAQnC,SAASyD,EAA0B,GAAtBF,EAAcnD,MAC5CiB,EAASc,QAAQnC,SAAS0D,EAAwB,GAApBH,EAAclD,KAI9CwC,OAAOkB,QAAQzC,EAAaa,SAASY,SAAQiB,IAAuB,IAArBC,EAAUC,GAAKF,EAC5D,IAAKE,EAAK9B,wBAA0B8B,EAAKC,sBAAuB,OAGhEtB,OAAOkB,QAAQxD,GAAawC,SAAQqB,IAA0B,IAAxBC,EAAYC,GAAMF,EACtD,GAAIF,EAAK9B,uBAAyB8B,EAAKC,sBAAuB,CAC5D,MAAMI,EAAaL,EAAK9B,sBAAsBiC,QAC3BG,IAAfD,IACFL,EAAKC,sBAAsBI,GAAcD,GAAS,EAEtD,KAIFzB,OAAOkB,QAAQvD,GAASuC,SAAQ0B,IAAsB,IAApBC,EAAQJ,GAAMG,EAC9C,GAAIP,EAAK9B,uBAAyB8B,EAAKC,sBAAuB,CAC5D,MAAMI,EAAaL,EAAK9B,sBAAsB,UAADuC,OAAWD,SACrCF,IAAfD,IACFL,EAAKC,sBAAsBI,GAAcD,GAAS,EAEtD,KAIF,MAAMM,EAAmE,CACvEC,MAAO,CAAEC,WAAY,GAAKC,cAAe,GAAKC,eAAgB,IAC9DC,IAAK,CAAEC,eAAgB,GAAKC,gBAAiB,GAAKC,WAAY,IAC9DC,MAAO,CAAEC,aAAc,GAAKC,cAAe,GAAKL,eAAgB,GAAKC,gBAAiB,IACtFK,UAAW,CAAEC,YAAa,GAAKC,aAAc,GAAKC,UAAW,GAAKC,YAAa,IAC/EC,WAAY,CAAEP,aAAc,GAAKC,cAAe,GAAKO,YAAa,KAiBpE,GAdIlB,EAAmBjE,IAAmBuD,EAAK9B,uBAAyB8B,EAAKC,uBAC3EtB,OAAOkB,QAAQa,EAAmBjE,IAAiBoC,SAAQgD,IAAyB,IAAvBC,EAAW1B,GAAMyB,EAC5E,MAAMxB,EAAaL,EAAK9B,sBAAuB4D,QAC5BxB,IAAfD,IAEFL,EAAKC,sBAAuBI,GAAcV,KAAKoC,IAC7C/B,EAAKC,sBAAuBI,GAC5BD,OAOJJ,EAAK9B,uBAAyB8B,EAAKC,sBAAuB,CAC5D,MACM+B,EAAgB,EAChBC,EAAQtC,KAAKC,IAAIV,EAAO8C,GAAiB,IAAO,EAAI,EACpDE,EAAYlC,EAAK9B,sBAAoC,aACrDiE,EAAanC,EAAK9B,sBAAqC,mBAC3CoC,IAAd4B,IAAyBlC,EAAKC,sBAAsBiC,GAAaD,QAClD3B,IAAf6B,IAA0BnC,EAAKC,sBAAsBkC,GAAcF,EACzE,QAICvF,GAGH0F,EAAAA,EAAAA,KAAA,SACEvG,SAAUA,EACVE,MAAOA,EACPD,SAAU,CAAC,IAAM,EAAG,GAAIuG,UAExBD,EAAAA,EAAAA,KAAA,aACEE,OAAQ5F,MATK,K,8GC5Od,SAAS6F,EAAqB7G,GAOL,IAPM,UACpCC,EAAS,aACTC,EAAY,SACZC,EAAW,CAAC,GAAI,EAAG,GAAE,MACrBE,EAAQ,CAAC,IAAK,IAAK,KAAI,qBACvBC,GAAuB,EAAK,OAC5BwG,GAAS,GACkB9G,EAC3B,MAAM,SAAE+G,IAAaC,EAAAA,EAAAA,OAEdrG,EAAasG,IAAkBC,EAAAA,EAAAA,UAAoC,CAAC,IACpEtG,EAASuG,IAAcD,EAAAA,EAAAA,UAAoC,CAAC,IAC5DnG,EAAgBqG,IAAqBF,EAAAA,EAAAA,UAAyF,YAC9HrG,EAAYwG,IAAiBH,EAAAA,EAAAA,WAAS,IACtCpG,EAAgBwG,IAAqBJ,EAAAA,EAAAA,UAAS,KAC9C3G,EAAcgH,IAAmBL,EAAAA,EAAAA,UAAS,CAAE1G,MAAO,EAAGC,IAAK,EAAGC,KAAM,IAgG3E,OA7FAkB,EAAAA,EAAAA,YAAU,KACR,IAAKf,EAEH,YADAsG,EAAW,CAAC,GAKd,MAAMK,EAAWC,aAAY,KAC3B,MAAMC,EAAiB,CAAC,KAAM,IAAK,IAAK,IAAK,IAAK,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,KAAM,MAG5FC,EAAwC,CAAC,EAC/CA,EAHsBD,EAAezD,KAAK2D,MAAM3D,KAAK4D,SAAWH,EAAejF,UAGnD,GAAsB,GAAhBwB,KAAK4D,SACvCV,EAAWQ,KACV,KAEH,MAAO,IAAMG,cAAcN,KAC1B,CAAC3G,KAGJe,EAAAA,EAAAA,YAAU,KAAO,IAADmG,EAAAC,EACd,IAAKjB,GAAgC,IAApBA,EAAStE,OAAc,OAExC,MAAMwF,EAAclB,EAASA,EAAStE,OAAS,GAgB/C,GAbyB,iBAArBwF,EAAYC,MAA2BpB,GACzCO,GAAc,GACdD,EAAkB,WAClBE,EAAkB,KACY,sBAArBW,EAAYC,MAAiCpB,EAIxB,sBAArBmB,EAAYC,MAAqD,kBAArBD,EAAYC,MACjEb,GAAc,IAJdA,GAAc,GACdD,EAAkB,SAClBE,EAAkB,KAMhB,WAAYW,GAAiC,QAAtBF,EAAIE,EAAYE,cAAM,IAAAJ,GAAS,QAATC,EAAlBD,EAAoBK,eAAO,IAAAJ,GAA3BA,EAA6BK,OAAQ,CAClE,MAAMA,EAASJ,EAAYE,OAAOC,QAAQC,OAGpCC,EAAWrF,OAAOkB,QAAQkE,GAAQE,MAAK,CAAAnE,EAAAI,KAAA,IAAE,CAAEgE,GAAEpE,GAAG,CAAEqE,GAAEjE,EAAA,OAAMiE,EAAgBD,KAChF,GAAIF,EAAS7F,OAAS,EAAG,CACvB,MAAOiG,GAAcJ,EAAS,GAYxBK,EATuD,CAC3D,IAAO,QACP,WAAc,UACd,QAAW,MACX,MAAS,QACT,SAAY,YACZ,cAAiB,cAGcD,GAC7BC,GACFvB,EAAkBuB,GAIpB,MAAMC,EAA4C,CAAC,EACnDN,EAASnF,SAAQ0B,IAAuB,IAArBgE,EAASC,GAAMjE,EAChC,MAAMkE,EAAiBF,EAAQxG,cAC3B0G,GAAmC,kBAAVD,IAC3BF,EAAeG,GAAkBD,MAGrC7B,EAAe2B,EACjB,CACF,IACC,CAAC7B,EAAUD,KAGdlF,EAAAA,EAAAA,YAAU,KACR,IAAKf,EAEH,YADA0G,EAAgB,CAAE/G,MAAO,EAAGC,IAAK,EAAGC,KAAM,IAI5C,MAAM8G,EAAWC,aAAY,KAC3BF,EAAgB,CACd/G,MAA+B,IAAvByD,KAAK4D,SAAW,IACxBpH,IAA6B,KAAvBwD,KAAK4D,SAAW,IACtBnH,KAA8B,KAAvBuD,KAAK4D,SAAW,QAExB,KAEH,MAAO,IAAMC,cAAcN,KAC1B,CAAC3G,KAGF6F,EAAAA,EAAAA,KAAC3G,EAAAA,sBAAqB,CACpBE,UAAWA,EACXC,aAAcA,EACdC,SAAUA,EACVE,MAAOA,EACPC,qBAAsBA,EACtBC,aAAcA,EACdI,YAAaA,EACbC,QAASA,EACTC,WAAYA,EACZC,eAAgBA,EAChBC,eAAgBA,GAGtB,C","sources":["components/RPMAvatarWithTracking.tsx","components/HumeAvatarIntegration.tsx"],"sourcesContent":["import React, { useEffect, useRef, useState } from 'react';\nimport { useGLTF, useAnimations } from '@react-three/drei';\nimport { useFrame } from '@react-three/fiber';\nimport * as THREE from 'three';\n// Temporarily disabled to prevent console errors\n// import { useWebcamTracking } from '../hooks/useWebcamTracking';\n\ninterface RPMAvatarWithTrackingProps {\n  avatarUrl: string;\n  animationUrl?: string;\n  position?: [number, number, number];\n  rotation?: [number, number, number];\n  scale?: [number, number, number];\n  \n  // Head tracking\n  enableWebcamTracking?: boolean;\n  headRotation?: { pitch: number; yaw: number; roll: number };\n  \n  // Facial expressions (0-1 values)\n  expressions?: {\n    happy?: number;\n    sad?: number;\n    angry?: number;\n    surprised?: number;\n    disgusted?: number;\n    fearful?: number;\n  };\n  \n  // Visemes for lip sync (0-1 values)\n  visemes?: {\n    aa?: number;\n    E?: number;\n    I?: number;\n    O?: number;\n    U?: number;\n    CH?: number;\n    DD?: number;\n    FF?: number;\n    kk?: number;\n    nn?: number;\n    PP?: number;\n    RR?: number;\n    SS?: number;\n    TH?: number;\n  };\n  \n  // Voice data\n  isSpeaking?: boolean;\n  voiceIntensity?: number;\n  \n  // Emotion from voice/context\n  emotionalState?: 'neutral' | 'happy' | 'sad' | 'excited' | 'thoughtful' | 'angry' | 'surprised';\n}\n\nexport const RPMAvatarWithTracking: React.FC<RPMAvatarWithTrackingProps> = ({\n  avatarUrl,\n  animationUrl,\n  position = [0, -0.4, 0], // Raise slightly to center face\n  rotation = [0, 0, 0], // Natural pose\n  scale = [1.2, 1.2, 1.2], // Slightly larger for close-up\n  enableWebcamTracking = false,\n  headRotation = { pitch: 0, yaw: 0, roll: 0 },\n  expressions = {},\n  visemes = {},\n  isSpeaking = false,\n  voiceIntensity = 0,\n  emotionalState = 'neutral',\n}) => {\n  const { scene } = useGLTF(avatarUrl);\n  const animationGltf = useGLTF(animationUrl || avatarUrl); // Always call the hook\n  const animClips = animationUrl ? animationGltf.animations : [];\n  const { actions } = useAnimations(animClips, scene);\n  \n  const headBone = useRef<THREE.Bone | null>(null);\n  const neckBone = useRef<THREE.Bone | null>(null);\n  const morphTargets = useRef<{ [key: string]: THREE.Mesh }>({});\n  \n  // Temporarily disable webcam tracking to prevent errors\n  const webcamTracking = {\n    rotation: { pitch: 0, yaw: 0, roll: 0 },\n    isWebcamActive: false,\n    error: null,\n    startWebcam: () => {},\n    stopWebcam: () => {}\n  };\n  \n  // Log webcam status\n  useEffect(() => {\n    if (enableWebcamTracking) {\n      console.log('Webcam tracking enabled:', webcamTracking.isWebcamActive);\n      if (webcamTracking.error) {\n        console.error('Webcam error:', webcamTracking.error);\n      }\n    }\n  }, [enableWebcamTracking, webcamTracking.isWebcamActive, webcamTracking.error]);\n  \n  // Find bones and morph targets\n  useEffect(() => {\n    if (scene) {\n      scene.traverse((child) => {\n        if (child instanceof THREE.Bone) {\n          const boneName = child.name.toLowerCase();\n          if (boneName.includes('head')) headBone.current = child;\n          else if (boneName.includes('neck')) neckBone.current = child;\n        }\n        \n        if (child instanceof THREE.SkinnedMesh && child.morphTargetDictionary) {\n          morphTargets.current[child.name] = child;\n        }\n      });\n    }\n  }, [scene]);\n  \n  // Play animations\n  useEffect(() => {\n    // Try different animation - use idle.glb instead of M_Standing_Idle_001.glb\n    if (actions && animClips.length > 0) {\n      // Find the best animation clip\n      const idleClip = animClips.find(clip => \n        clip.name.toLowerCase().includes('idle') || \n        clip.name.toLowerCase().includes('standing')\n      );\n      const clipToPlay = idleClip || animClips[0];\n      actions[clipToPlay.name]?.reset().fadeIn(0.2).play();\n    }\n    return () => {\n      Object.values(actions).forEach((action) => action?.stop());\n    };\n  }, [actions, animClips]);\n  \n  // Apply all transformations\n  useFrame((state) => {\n    const time = state.clock.getElapsedTime();\n    \n    // Combine head rotations\n    let finalRotation = { ...headRotation };\n    if (enableWebcamTracking) {\n      finalRotation.pitch += webcamTracking.rotation.pitch;\n      finalRotation.yaw += webcamTracking.rotation.yaw;\n      finalRotation.roll += webcamTracking.rotation.roll;\n    }\n    \n    // Apply head rotation\n    if (headBone.current) {\n      // Base forward tilt to prevent backward lean\n      headBone.current.rotation.x = 0.3; // Forward tilt for T-pose\n      headBone.current.rotation.y = THREE.MathUtils.lerp(\n        headBone.current.rotation.y,\n        finalRotation.yaw * 0.7,\n        0.1\n      );\n      headBone.current.rotation.z = THREE.MathUtils.lerp(\n        headBone.current.rotation.z,\n        finalRotation.roll * 0.3,\n        0.1\n      );\n      \n      // Add subtle movements based on emotional state\n      switch(emotionalState) {\n        case 'happy':\n          headBone.current.rotation.y += Math.sin(time * 2) * 0.02;\n          break;\n        case 'sad':\n          headBone.current.rotation.y -= 0.1;\n          break;\n        case 'excited':\n          headBone.current.rotation.z += Math.sin(time * 4) * 0.03;\n          break;\n        case 'thoughtful':\n          headBone.current.rotation.x += Math.sin(time * 0.5) * 0.02;\n          break;\n        case 'angry':\n          headBone.current.rotation.y -= 0.05;\n          break;\n        case 'surprised':\n          headBone.current.rotation.y += 0.05;\n          break;\n      }\n      \n      // Add speaking motion\n      if (isSpeaking) {\n        headBone.current.rotation.y += Math.sin(time * 8) * voiceIntensity * 0.03;\n      }\n    }\n    \n    // Apply neck rotation (softer)\n    if (neckBone.current) {\n      neckBone.current.rotation.x = finalRotation.pitch * 0.3;\n      neckBone.current.rotation.y = finalRotation.yaw * 0.3;\n    }\n    \n    // Apply facial expressions and visemes\n    Object.entries(morphTargets.current).forEach(([meshName, mesh]) => {\n      if (!mesh.morphTargetDictionary || !mesh.morphTargetInfluences) return;\n      \n      // Apply expressions\n      Object.entries(expressions).forEach(([expression, value]) => {\n        if (mesh.morphTargetDictionary && mesh.morphTargetInfluences) {\n          const morphIndex = mesh.morphTargetDictionary[expression];\n          if (morphIndex !== undefined) {\n            mesh.morphTargetInfluences[morphIndex] = value || 0;\n          }\n        }\n      });\n      \n      // Apply visemes (mouth shapes for speech)\n      Object.entries(visemes).forEach(([viseme, value]) => {\n        if (mesh.morphTargetDictionary && mesh.morphTargetInfluences) {\n          const morphIndex = mesh.morphTargetDictionary[`viseme_${viseme}`];\n          if (morphIndex !== undefined) {\n            mesh.morphTargetInfluences[morphIndex] = value || 0;\n          }\n        }\n      });\n      \n      // Apply emotion-based expressions\n      const emotionExpressions: { [key: string]: { [key: string]: number } } = {\n        happy: { mouthSmile: 0.7, eyeSquintLeft: 0.3, eyeSquintRight: 0.3 },\n        sad: { mouthFrownLeft: 0.5, mouthFrownRight: 0.5, eyesClosed: 0.2 },\n        angry: { browDownLeft: 0.8, browDownRight: 0.8, mouthFrownLeft: 0.3, mouthFrownRight: 0.3 },\n        surprised: { eyeWideLeft: 0.8, eyeWideRight: 0.8, mouthOpen: 0.5, browInnerUp: 0.7 },\n        thoughtful: { browDownLeft: 0.2, browDownRight: 0.2, mouthPucker: 0.2 },\n      };\n      \n      if (emotionExpressions[emotionalState] && mesh.morphTargetDictionary && mesh.morphTargetInfluences) {\n        Object.entries(emotionExpressions[emotionalState]).forEach(([morphName, value]) => {\n          const morphIndex = mesh.morphTargetDictionary![morphName];\n          if (morphIndex !== undefined) {\n            // Blend with existing value\n            mesh.morphTargetInfluences![morphIndex] = Math.max(\n              mesh.morphTargetInfluences![morphIndex],\n              value\n            );\n          }\n        });\n      }\n      \n      // Natural blinking\n      if (mesh.morphTargetDictionary && mesh.morphTargetInfluences) {\n        const blinkSpeed = 0.15;\n        const blinkInterval = 4;\n        const blink = Math.sin(time * blinkInterval) > 0.95 ? 1 : 0;\n        const blinkLeft = mesh.morphTargetDictionary['eyeBlinkLeft'];\n        const blinkRight = mesh.morphTargetDictionary['eyeBlinkRight'];\n        if (blinkLeft !== undefined) mesh.morphTargetInfluences[blinkLeft] = blink;\n        if (blinkRight !== undefined) mesh.morphTargetInfluences[blinkRight] = blink;\n      }\n    });\n  });\n  \n  if (!scene) return null;\n  \n  return (\n    <group \n      position={position} \n      scale={scale}\n      rotation={[0.05, 0, 0]} // Very subtle forward tilt\n    >\n      <primitive \n        object={scene} \n      />\n    </group>\n  );\n}\n","import React from 'react';\nimport { useState, useEffect } from 'react';\nimport { useVoice } from '@humeai/voice-react';\nimport { RPMAvatarWithTracking } from './RPMAvatarWithTracking';\n\ninterface HumeAvatarIntegrationProps {\n  avatarUrl: string;\n  animationUrl?: string;\n  position?: [number, number, number];\n  scale?: [number, number, number];\n  enableWebcamTracking?: boolean;\n  isUser?: boolean; // true for user avatar, false for NPC\n}\n\nexport function HumeAvatarIntegration({\n  avatarUrl,\n  animationUrl,\n  position = [0, -1, 0],\n  scale = [1.2, 1.2, 1.2],\n  enableWebcamTracking = false,\n  isUser = false,\n}: HumeAvatarIntegrationProps) {\n  const { messages } = useVoice();\n  \n  const [expressions, setExpressions] = useState<{ [key: string]: number }>({});\n  const [visemes, setVisemes] = useState<{ [key: string]: number }>({});\n  const [emotionalState, setEmotionalState] = useState<'neutral' | 'happy' | 'sad' | 'excited' | 'thoughtful' | 'angry' | 'surprised'>('neutral');\n  const [isSpeaking, setIsSpeaking] = useState(false);\n  const [voiceIntensity, setVoiceIntensity] = useState(0.5);\n  const [headRotation, setHeadRotation] = useState({ pitch: 0, yaw: 0, roll: 0 });\n  \n  // Simple viseme animation based on speaking state\n  useEffect(() => {\n    if (!isSpeaking) {\n      setVisemes({});\n      return;\n    }\n    \n    // Animate visemes while speaking\n    const interval = setInterval(() => {\n      const visemeSequence = ['aa', 'E', 'I', 'O', 'U', 'PP', 'FF', 'TH', 'DD', 'kk', 'CH', 'SS', 'nn', 'RR'];\n      const currentViseme = visemeSequence[Math.floor(Math.random() * visemeSequence.length)];\n      \n      const newVisemes: { [key: string]: number } = {};\n      newVisemes[currentViseme] = 0.6 + Math.random() * 0.4;\n      setVisemes(newVisemes);\n    }, 100);\n    \n    return () => clearInterval(interval);\n  }, [isSpeaking]);\n  \n  // Track speaking state from messages\n  useEffect(() => {\n    if (!messages || messages.length === 0) return;\n    \n    const lastMessage = messages[messages.length - 1];\n    \n    // Simple speaking detection based on message type\n    if (lastMessage.type === 'user_message' && isUser) {\n      setIsSpeaking(true);\n      setEmotionalState('neutral');\n      setVoiceIntensity(0.7);\n    } else if (lastMessage.type === 'assistant_message' && !isUser) {\n      setIsSpeaking(true);\n      setEmotionalState('happy');\n      setVoiceIntensity(0.6);\n    } else if (lastMessage.type === 'user_interruption' || lastMessage.type === 'assistant_end') {\n      setIsSpeaking(false);\n    }\n    \n    // Extract emotions if available\n    if ('models' in lastMessage && lastMessage.models?.prosody?.scores) {\n      const scores = lastMessage.models.prosody.scores;\n      \n      // Map Hume emotions to our emotional states\n      const emotions = Object.entries(scores).sort(([, a], [, b]) => (b as number) - (a as number));\n      if (emotions.length > 0) {\n        const [topEmotion] = emotions[0];\n        \n        // Simple emotion mapping\n        const emotionMap: { [key: string]: typeof emotionalState } = {\n          'Joy': 'happy',\n          'Excitement': 'excited',\n          'Sadness': 'sad',\n          'Anger': 'angry',\n          'Surprise': 'surprised',\n          'Contemplation': 'thoughtful',\n        };\n        \n        const mappedEmotion = emotionMap[topEmotion];\n        if (mappedEmotion) {\n          setEmotionalState(mappedEmotion);\n        }\n        \n        // Set expression values\n        const newExpressions: { [key: string]: number } = {};\n        emotions.forEach(([emotion, score]) => {\n          const expressionName = emotion.toLowerCase();\n          if (expressionName && typeof score === 'number') {\n            newExpressions[expressionName] = score;\n          }\n        });\n        setExpressions(newExpressions);\n      }\n    }\n  }, [messages, isUser]);\n  \n  // Simulate head movement based on speaking\n  useEffect(() => {\n    if (!isSpeaking) {\n      setHeadRotation({ pitch: 0, yaw: 0, roll: 0 });\n      return;\n    }\n    \n    const interval = setInterval(() => {\n      setHeadRotation({\n        pitch: (Math.random() - 0.5) * 0.1,\n        yaw: (Math.random() - 0.5) * 0.15,\n        roll: (Math.random() - 0.5) * 0.05,\n      });\n    }, 500);\n    \n    return () => clearInterval(interval);\n  }, [isSpeaking]);\n  \n  return (\n    <RPMAvatarWithTracking\n      avatarUrl={avatarUrl}\n      animationUrl={animationUrl}\n      position={position}\n      scale={scale}\n      enableWebcamTracking={enableWebcamTracking}\n      headRotation={headRotation}\n      expressions={expressions}\n      visemes={visemes}\n      isSpeaking={isSpeaking}\n      voiceIntensity={voiceIntensity}\n      emotionalState={emotionalState}\n    />\n  );\n}\n"],"names":["RPMAvatarWithTracking","_ref","avatarUrl","animationUrl","position","rotation","scale","enableWebcamTracking","headRotation","pitch","yaw","roll","expressions","visemes","isSpeaking","voiceIntensity","emotionalState","scene","useGLTF","animationGltf","animClips","animations","actions","useAnimations","headBone","useRef","neckBone","morphTargets","webcamTracking","useEffect","console","log","error","traverse","child","THREE","boneName","name","toLowerCase","includes","current","morphTargetDictionary","length","_actions$clipToPlay$n","clipToPlay","find","clip","reset","fadeIn","play","Object","values","forEach","action","stop","useFrame","state","time","clock","getElapsedTime","finalRotation","_objectSpread","x","y","lerp","z","Math","sin","entries","_ref2","meshName","mesh","morphTargetInfluences","_ref3","expression","value","morphIndex","undefined","_ref4","viseme","concat","emotionExpressions","happy","mouthSmile","eyeSquintLeft","eyeSquintRight","sad","mouthFrownLeft","mouthFrownRight","eyesClosed","angry","browDownLeft","browDownRight","surprised","eyeWideLeft","eyeWideRight","mouthOpen","browInnerUp","thoughtful","mouthPucker","_ref5","morphName","max","blinkInterval","blink","blinkLeft","blinkRight","_jsx","children","object","HumeAvatarIntegration","isUser","messages","useVoice","setExpressions","useState","setVisemes","setEmotionalState","setIsSpeaking","setVoiceIntensity","setHeadRotation","interval","setInterval","visemeSequence","newVisemes","floor","random","clearInterval","_lastMessage$models","_lastMessage$models$p","lastMessage","type","models","prosody","scores","emotions","sort","a","b","topEmotion","mappedEmotion","newExpressions","emotion","score","expressionName"],"sourceRoot":""}