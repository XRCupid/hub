{"version":3,"file":"static/js/7588.204f077d.chunk.js","mappings":"uOA2G0CA,EAAAA,EAAyBC,QAAO,CAACC,EAAoBC,KAC7FD,EAAIC,GAAO,EACJD,IACN,CAAC,GAG4CF,EAAAA,EAAyBC,QAAO,CAACC,EAA6BC,KAChG,iBAARA,GAAkC,kBAARA,IAE5BD,EAAIC,GAAO,GAEND,IACN,CAAC,GAhCJ,MAgHME,EAA0B,CAC9B,2CACA,2CACA,2CACA,2CACA,2CACA,2CACA,2CACA,2CACA,2CACA,2CACA,wBAGIC,EAA0B,CAC9B,sCACA,sCACA,iDACA,iDACA,iDACA,iDACA,iDACA,iDACA,iDACA,iDACA,iDACA,iDACA,wBAMIC,EAAmC,CACvCC,WAAY,kBACZC,OAAQ,kBACRC,aAAc,MACdC,QAAS,WACTC,MAAO,QACPC,OAAQ,UACRC,SAAU,QACVC,OAAQ,OAGJC,EAAyBC,EAAAA,YAG7B,CAACC,EAAOC,KAER,MAAOC,EAAOC,IAAYC,EAAAA,EAAAA,WAA8B,MACtDC,SAAS,EACTC,YAAY,EACZC,WAAW,EACXC,YAAY,EACZC,SAAU,GACVC,WAAY,GACZC,YAAY,EACZC,oBAAoB,EACpBC,oBAAqB,GACrBC,cAAe,kBACfC,cAAe,OACfC,eAAgB,kBAChBC,oBAAqB,CAAC,EACtBC,kBAAmB,CAAC,EACpBC,aAAcnB,EAAMmB,aACpBC,eAAgB,KAChBC,MAAO,KACPC,WAAW,EACXC,UAAWvB,EAAMwB,gBAAkB,WACnCC,iBAAiB,EACjBC,YAAY,EACZC,UAAU,EACVC,0BAA2B,CAAC,OAI5BnB,SAAUoB,EACVC,cAAeC,EACfC,WAAYC,EACZC,UAAWC,EACXC,WAAYC,EACZC,QAASC,EAAY,OACrBC,IACEC,EAAAA,EAAAA,MAEEC,GAAiBC,EAAAA,EAAAA,QAAY,MAC7BC,GAAiBD,EAAAA,EAAAA,QAAuB,MACxCE,GAAgBF,EAAAA,EAAAA,QAAyB,OAG/CG,EAAAA,EAAAA,YAAU,KACR,GAAI5C,EAAMiB,aAAc,CACtB4B,QAAQC,IAAI,8DAADC,OAA+D/C,EAAMiB,aAAY,qBAChE+B,WAC1B,MAAMC,GAAKC,EAAAA,EAAAA,MACLC,GAAYC,EAAAA,EAAAA,IAAIH,EAAI,cAAejD,EAAMiB,cAC/C,IACE,MAAMoC,QAAgBC,EAAAA,EAAAA,IAAOH,GAC7B,GAAIE,EAAQE,SAAU,CACpB,MAAMC,EAAcH,EAAQI,OAC5BZ,QAAQC,IAAI,oDAAqDU,GACjEvD,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GACRD,GAAI,IACPxC,eAAgBsC,EAEhBnC,UAAWmC,EAAYnC,WAAaqC,EAAKrC,UACzCF,MAAO,QAEX,MACE0B,QAAQ1B,MAAM,4DAA6DnB,EAAMiB,cACjFhB,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAEvC,MAAO,wBAAyBD,eAAgB,QAEjF,CAAE,MAAO0C,GACPf,QAAQ1B,MAAM,+DAAgEyC,GAC9E3D,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAEvC,MAAO,mCAAoCD,eAAgB,QAC1F,GAEF2C,EACF,MACEhB,QAAQC,IAAI,kGAEZ7C,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAExC,eAAgB,KAAMG,UAAWvB,EAAMwB,gBAAkB,iBAEvF,CAACtB,EAAMiB,aAAcnB,EAAMwB,iBAG9B,MAAMwC,GAAsBC,EAAAA,EAAAA,cAAaH,IACvC3D,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAEvC,MAAO,mBAAuB,OAAHyC,QAAG,IAAHA,OAAG,EAAHA,EAAKI,UAAWJ,SACvE,IACGK,GAAqBF,EAAAA,EAAAA,cAAY,QAEpC,IACGG,GAAoCH,EAAAA,EAAAA,cAAY,CAACI,EAAcC,KAEnEnE,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAE9C,cAAc,8BAADmC,OAAgCoB,EAAI,WAC7E,IACGE,GAAoBN,EAAAA,EAAAA,cAAaO,IACrCA,EAAEC,iBAEFtE,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAE9C,cAAe,sBAC3C,IACG4D,GAAoBT,EAAAA,EAAAA,cAAaO,IACrCrE,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAElD,WAAY8D,EAAEG,OAAOC,YACjD,IACGC,GAAaZ,EAAAA,EAAAA,cAAY,KAC7B9D,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAEjC,UAAWiC,EAAKjC,eAC5C,IACGmD,GAAYb,EAAAA,EAAAA,cAAY,KAC5B9D,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAElC,YAAakC,EAAKlC,iBAC9C,IACGqD,GAAcd,EAAAA,EAAAA,cAAY,KAC9B9D,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAErD,WAAYqD,EAAKrD,gBAC7C,IACGyE,GAAoBf,EAAAA,EAAAA,cAAY,KACpC9D,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAEjD,YAAY,EAAOC,oBAAoB,QACnE,IACGqE,GAAwBhB,EAAAA,EAAAA,cAAY,KACxC9D,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAEhD,oBAAoB,QAChD,IACGsE,GAAwBjB,EAAAA,EAAAA,cAAY,KACxC9D,GAASyD,IAAIC,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAUD,GAAI,IAAEvC,MAAO,0BACnC,IAGG8D,EAAoBjF,EAAMS,YAAcT,EAAMU,oBAAsBuB,EAI1E,OADAY,QAAQC,IAAI,6BAA8B9C,EAAMqB,YAE9C6D,EAAAA,EAAAA,MAAA,OAAKC,MAAO,CAAEC,QAAS,OAAQC,cAAe,MAAOC,OAAQ,OAAQC,SAAU,YAAaC,SAAA,EAE1FC,EAAAA,EAAAA,KAACC,EAAAA,QAAmB,CAElB3F,IAAKyC,EACLnB,UAAWrB,EAAMqB,UACjBZ,WAAYwE,EACZU,iBAAkB3F,EAAMW,oBACxBiF,WAAY5F,EAAMe,oBAClB8E,kBAAmB7F,EAAM0B,0BACzBoE,cAAe9F,EAAMuB,gBACrBwE,mBAAoB9G,EACpB+G,mBAAoB9G,EACpB+G,QAASnC,EACToC,OAAQjC,GAXHjE,EAAMqB,YAaboE,EAAAA,EAAAA,KAAA,UACEU,QAASA,IAAMjC,EAAkC,+BAAgClE,EAAMc,gBAAkB,qBACzGqE,OAAKxB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAOxE,GAAW,IAAEoG,SAAU,WAAYa,IAAK,OAAQC,KAAM,OAAQC,OAAQ,KAAKd,SACxF,iBAIAxF,EAAMyB,WACLyD,EAAAA,EAAAA,MAAA,OAAKqB,UAAU,UAAUpB,MAAO,CAC9BqB,MAAO,QACPC,SAAU,QACVrH,WAAY,yBACZI,MAAO,QACP4F,QAAS,OACTC,cAAe,SACf9F,QAAS,OACTmH,WAAY,oBACZC,UAAW,aACXpB,SAAU,WACVqB,MAAO,EACPR,IAAK,EACLS,OAAQ,EACRP,OAAQ,EACRQ,WAAY,6BACZC,UAAW,kBACXvB,SAAA,EACAN,EAAAA,EAAAA,MAAA,OAAKqB,UAAU,gBAAgBpB,MAAO,CAAE6B,SAAU,EAAGC,UAAW,OAAQC,aAAc,OAAQC,aAAc,QAAS3B,SAAA,CAClHxF,EAAMO,SAAS6G,KAAKC,IACnBnC,EAAAA,EAAAA,MAAA,OAAkBqB,UAAS,WAAAxD,OAAasE,EAAIC,QAAUnC,MAAO,CAC3D+B,aAAc,OACd3H,QAAS,YACTD,aAAc,OACdiI,SAAU,MACVC,UAA0B,SAAfH,EAAIC,OAAoB,WAAa,aAChDlI,WAA2B,SAAfiI,EAAIC,OAAoB,UAAY,UAChD9H,MAAO,QACPiI,UAAW,6BACXC,SAAU,aACVhI,SAAU,UACV8F,SAAA,CACC6B,EAAIlD,KACJkD,EAAIM,UAAWzC,EAAAA,EAAAA,MAAA,MAAIC,MAAO,CAAEzF,SAAU,QAAS0F,QAAS,QAASwC,QAAS,GAAKC,UAAW,OAAQrC,SAAA,CAAC,IAAE6B,EAAIM,QAAQ,SAb1GN,EAAIS,OAgBhBrC,EAAAA,EAAAA,KAAA,OAAK1F,IAAK2C,QAEZ+C,EAAAA,EAAAA,KAAA,SACE1F,IAAK4C,EACLoF,QAAShD,EACTkB,QAASjB,EACTG,MAAO,CAAEC,QAAS,WAEpBF,EAAAA,EAAAA,MAAA,QAAM8C,SAAU3D,EAAmBc,MAAO,CAAEC,QAAS,OAAQyC,UAAW,OAAQI,WAAY,OAAQC,UAAW,oBAAqBC,WAAY,GAAI3C,SAAA,EAClJC,EAAAA,EAAAA,KAAA,SACE2C,KAAK,OACLC,YAAY,uBACZ3D,MAAO1E,EAAMQ,WACb8H,SAAU9D,EACVW,MAAO,CAAEoD,KAAM,EAAGhJ,QAAS,OAAQD,aAAc,MAAOD,OAAQ,OAAQmJ,QAAS,OAAQC,YAAa,MAAOrJ,WAAY,UAAWI,MAAO,YAE7IiG,EAAAA,EAAAA,KAAA,UAAQ2C,KAAK,SAASjD,OAAKxB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAOxE,GAAW,IAAEC,WAAY,UAAWO,OAAQ,IAAI6F,UAChFC,EAAAA,EAAAA,KAACiD,EAAAA,IAAY,aAMnB1I,EAAMyB,WACNgE,EAAAA,EAAAA,KAAA,UACEU,QAASxB,EACTQ,MAAO,CACLI,SAAU,WACVsB,OAAQ,OACRD,MAAO,OACPxH,WAAY,UACZI,MAAO,QACPH,OAAQ,OACRC,aAAc,MACdkH,MAAO,OACPlB,OAAQ,OACRF,QAAS,OACTuD,WAAY,SACZC,eAAgB,SAChBnJ,OAAQ,UACRgI,UAAW,6BACXnB,OAAQ,GACRQ,WAAY,uBAEd+B,YAAavE,GAAMA,EAAEwE,cAAc3D,MAAM4B,UAAY,aACrDgC,WAAYzE,GAAMA,EAAEwE,cAAc3D,MAAM4B,UAAY,WAAYvB,SACjE,UAKHN,EAAAA,EAAAA,MAAA,OAAKqB,UAAU,eAAepB,MAAO,CACnCC,QAAS,OACTwD,eAAgB,SAChBD,WAAY,SACZpJ,QAAS,OACTH,WAAY,UACZ+I,WAAY,EACZa,IAAK,QACLxD,SAAA,EACAN,EAAAA,EAAAA,MAAA,UAAQiB,QAASvB,EAAWO,MAAOhG,EAAa8J,MAAOjJ,EAAMwB,WAAa,oBAAsB,kBAAkBgE,SAAA,CAC/GxF,EAAMwB,YAAaiE,EAAAA,EAAAA,KAACyD,EAAAA,IAAiB,KAAMzD,EAAAA,EAAAA,KAAC0D,EAAAA,IAAY,IAAI,IAAEnJ,EAAMwB,WAAa,UAAY,aAEhG0D,EAAAA,EAAAA,MAAA,UAAQiB,QAAStB,EAAaM,MAAOhG,EAAa8J,MAAOjJ,EAAMK,UAAY,aAAe,eAAemF,SAAA,CACtGxF,EAAMK,WAAYoF,EAAAA,EAAAA,KAAC2D,EAAAA,IAAU,KAAM3D,EAAAA,EAAAA,KAAC4D,EAAAA,IAAY,IAAI,IAAErJ,EAAMK,UAAY,WAAa,gBAExF6E,EAAAA,EAAAA,MAAA,UAAQiB,QAASrB,EAAmBK,OAAKxB,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAAMxE,GAAW,IAAEC,WAAY,YAAY6J,MAAM,kCAAiCzD,SAAA,EACzHC,EAAAA,EAAAA,KAAC6D,EAAAA,IAAY,IAAG,8BAObC,EAAiDzJ,IAC5D,MAAO0J,EAA2BC,IAAgCvJ,EAAAA,EAAAA,UAAiB,oBAC7EwJ,GAAkBjH,EAAAA,EAAAA,QAAqC,MACvDkH,EAAa9J,EAAAA,SAAc,KAC/B,MAAMb,EAAM4K,mDAIZ,OAAO5K,GAAO,KACb,IAEG6K,EAAe,uCAKfC,GAAkB/F,EAAAA,EAAAA,cAAY,KAClClB,QAAQC,IAAI,qDACX,IAEGiH,GAAYC,EAAAA,EAAAA,UAAQ,MACxB5B,KAAM,SACN1D,MAAOiF,KACL,CAACA,IAECM,GAAqBlG,EAAAA,EAAAA,cAAaC,IACtC,MAAMkG,EAAclG,EAAQoE,KAI5B,OAFAvF,QAAQC,IAAI,uCAADC,OAAwCmH,IAE3CA,GACN,IAAK,oBAEH,GADArH,QAAQC,IAAI,wCAAyCkB,GACjDA,EAAQmG,OAAQ,CAClB,MAAMC,EAAcpG,EAAQmG,OACxBC,EAAYC,MAAQD,EAAYC,KAAKC,aAEvCzH,QAAQC,IAAI,qCAAsCsH,EAAYC,KAAKC,YAMvE,CACA,MACF,IAAK,oBACHzH,QAAQC,IAAI,wCAAyCkB,GACrD,MACF,IAAK,YACHnB,QAAQC,IAAI,gCAAiCkB,GAC7C,MACF,IAAK,gBACHnB,QAAQC,IAAI,oCAAqCkB,GACjD,MACF,IAAK,aACHnB,QAAQ1B,MAAM,iCAAkC6C,MAUnD,IAEGuG,GAAmBxG,EAAAA,EAAAA,cAAaO,IAAY,IAADkG,EAC/C3H,QAAQC,IAAI,wDAAyDwB,EAAEmG,KAAM,UAAWnG,EAAEoG,OAAQ,YAAapG,EAAEqG,UAC1F,QAAvBH,EAAAd,EAAgBkB,eAAO,IAAAJ,GAAvBA,EAAyBK,0BACxB,IAEGC,GAAmB/G,EAAAA,EAAAA,cAAa5C,IACpC,IAAI4J,EAAU,0CAAAhI,OAA6C5B,EAAMiH,KAAI,YAAArF,OAAW5B,EAAMsJ,KAAI,eAAA1H,OAAc5B,EAAM6C,SAC9GnB,QAAQ1B,MAAM4J,EAAY5J,KACzB,IAWH,OATKwI,GACF9G,QAAQmI,KAAK,8FAKhBnI,QAAQC,IAAI,uEAADC,OAAwE4G,EAAU,sBAAA5G,OAAqB8G,EAAY,MAC9HhH,QAAQC,IAAI,kDAAmDiH,IAG7D7E,EAAAA,EAAAA,MAAA+F,EAAAA,SAAA,CAAAzF,SAAA,EACEN,EAAAA,EAAAA,MAAA,OAAKC,MAAO,CAAE5F,QAAS,MAAO2L,gBAAiB,UAAW1L,MAAO,QAAS2L,UAAW,SAAUC,WAAY,OAAQ1L,SAAU,QAAS4G,OAAQ,KAAMf,SAAU,YAAaC,SAAA,CAAC,4BAChJgE,MAE5B/D,EAAAA,EAAAA,KAAC4F,EAAAA,GAAa,CACdC,aAAcA,KACZzI,QAAQC,IAAI,mDACZ2G,EAA6B,wBAE/B8B,WAAYA,KACV1I,QAAQC,IAAI,iDACZ2G,EAA6B,sBAE/B+B,KAAMzB,EACN0B,SAAU5B,EACV6B,OAAO,EACPC,OAAQ7B,EACR8B,UAAW3B,EACX4B,QAAStB,EACTtE,QAAS6E,EAAiBtF,UAE1BC,EAAAA,EAAAA,KAAC7F,EAAsB,CACnBG,IAAK2J,EACLpI,eAAgBxB,EAAMwB,eACtBL,aAAcnB,EAAMmB,aAGpB4I,aAAcA,S","sources":["components/SimulationView_backup_20250528_163301.tsx"],"sourcesContent":["import process from 'process';\nimport React, { useCallback, useEffect, useMemo, useRef, useState, useContext, useImperativeHandle } from 'react';\nimport { useParams, useNavigate } from 'react-router-dom';\nimport { getFirestore, Timestamp, doc, getDoc, updateDoc, arrayUnion } from 'firebase/firestore';\nimport * as Hume from 'hume';\n\nimport { v4 as uuidv4 } from 'uuid';\nimport { \n  FaMicrophone, \n  FaMicrophoneSlash, \n  FaVolumeUp, \n  FaVolumeMute, \n  FaPaperPlane, \n  FaTimes, \n  FaExpand, \n  FaCompress, \n  FaCommentDots, \n  FaCog, \n  FaPlay, \n  FaPause, \n  FaRedo, \n  FaStopCircle \n} from 'react-icons/fa';\nimport { IoMdSend } from 'react-icons/io';\nimport { Canvas } from '@react-three/fiber';\nimport { OrbitControls } from '@react-three/drei';\nimport { Group, Vector3 } from 'three';\nimport * as THREE from 'three';\nimport { VoiceProvider, useVoice, VoiceReadyState, type JSONMessage, type ConnectionMessage } from '@humeai/voice-react'; // Assuming JSONMessage is exported\n\nimport { useAuth } from '../contexts/AuthContext';\nimport { useUser } from '../contexts/UserContext';\nimport firebase from 'firebase/app';\nimport 'firebase/firestore';\nimport ReadyPlayerMeAvatar from './ReadyPlayerMeAvatar';\nimport EmotionDrivenAvatar, { type Emotion } from './EmotionDrivenAvatar';\nimport { prosodyToBlendshapes } from '../utils/prosodyToBlendshapes';\n\nimport { ARKitBlendshapeNamesList, type BlendShapeMap, type BlendshapeKey } from '../types/blendshapes';\nimport { useHumeEmotionStream } from '../hooks/useHumeEmotionStream';\nimport { initializeAzureSdk, synthesizeSpeechWithVisemes as untypedSynthesizeSpeechWithVisemes, VisemeEvent } from '../services/VisemeService';\n// import { saveChatMessageToFirebase } from '../firebase/firebaseServices'; \n// import { getTopEmotion } from '../utils/emotionMappings'; // emotionToBlendshapes removed, getTopEmotion also unused due to local definition\nimport * as SpeechSDK from 'microsoft-cognitiveservices-speech-sdk'; \n\n\n// Data structures from VisemeService.js\ninterface BlendshapeFrame {\n  frameIndex: number; // Absolute frame index\n  shapes: number[];   // Array of 55 blendshape values\n  audioOffset: number; // In milliseconds, from the start of the audio\n}\n\ninterface StandardViseme {\n  visemeID: number;\n  audioOffset: number; // In milliseconds, already converted by VisemeService\n}\n\ninterface VisemeData {\n  standardVisemes: StandardViseme[];\n  blendShapeFrames: BlendshapeFrame[];\n}\n\ninterface VisemeServiceResult {\n  audioData: ArrayBuffer;\n  visemeData: VisemeData;\n}\n\n// The old AzureViseme and AzureVisemeAnimation interfaces might be removable if no longer used\n// For now, keeping them commented out or to be removed if prepareVisemeFrames fully transitions\n/*\ninterface SpeakTextWithVisemesResult {\n  audioData: ArrayBuffer; \n  visemes: AzureViseme[]; \n}\ninterface AzureVisemeAnimation {\n  frameIndex: number;\n  blendShapes: number[][];\n}\ninterface AzureViseme {\n  audioOffset: number; \n  visemeID: number;\n  animation?: AzureVisemeAnimation | null; \n}\n*/\n\n// ARKit blendshape names corresponding to Azure's 55 blendshapes\nconst ARKIT_BLENDSHAPE_NAMES_AZURE = [\n  \"browDownLeft\", \"browDownRight\", \"browInnerUp\", \"browOuterUpLeft\", \"browOuterUpRight\",\n  \"cheekPuff\", \"cheekSquintLeft\", \"cheekSquintRight\", \"eyeBlinkLeft\", \"eyeBlinkRight\",\n  \"eyeLookDownLeft\", \"eyeLookDownRight\", \"eyeLookInLeft\", \"eyeLookInRight\", \"eyeLookOutLeft\",\n  \"eyeLookOutRight\", \"eyeLookUpLeft\", \"eyeLookUpRight\", \"eyeSquintLeft\", \"eyeSquintRight\",\n  \"eyeWideLeft\", \"eyeWideRight\", \"jawForward\", \"jawLeft\", \"jawOpen\", \"jawRight\",\n  \"mouthClose\", \"mouthDimpleLeft\", \"mouthDimpleRight\", \"mouthFrownLeft\", \"mouthFrownRight\",\n  \"mouthFunnel\", \"mouthLeft\", \"mouthLowerDownLeft\", \"mouthLowerDownRight\", \"mouthPressLeft\",\n  \"mouthPressRight\", \"mouthPucker\", \"mouthRight\", \"mouthRollLower\", \"mouthRollUpper\",\n  \"mouthShrugLower\", \"mouthShrugUpper\", \"mouthSmileLeft\", \"mouthSmileRight\", \"mouthStretchLeft\",\n  \"mouthStretchRight\", \"mouthUpperUpLeft\", \"mouthUpperUpRight\", \"noseSneerLeft\", \"noseSneerRight\",\n  // Assuming the last 3 are for tongue, though Azure docs might need to be checked for exact mapping\n  \"tongueOut\", \"tongueUp\", \"tongueDown\" // Placeholder if 55th is tongue related, adjust as needed\n];\n\nconst FRAME_RATE_HZ = 50; // Azure viseme animation frame rate\nconst FRAME_DURATION_MS = 1000 / FRAME_RATE_HZ;\nconst BLENDSHAPE_AMPLIFICATION_FACTOR = 1.5; // Adjusted for more natural amplification\n\n// Define default blendshapes for initialization\nconst defaultBlendShapes: BlendShapeMap = ARKitBlendshapeNamesList.reduce((acc: BlendShapeMap, key: BlendshapeKey) => {\n  acc[key] = 0;\n  return acc;\n}, {} as BlendShapeMap);\n\n// Define blendshapes for idle state, allowing autonomous blinking\nconst idleBlendShapes: Partial<BlendShapeMap> = ARKitBlendshapeNamesList.reduce((acc: Partial<BlendShapeMap>, key: BlendshapeKey) => {\n  if (key !== 'eyeBlinkLeft' && key !== 'eyeBlinkRight') {\n    // Initialize non-blink shapes to 0, consistent with defaultBlendShapes for those keys\n    acc[key] = 0;\n  }\n  return acc;\n}, {} as Partial<BlendShapeMap>);\n\n// Processed animation keyframe structure\ninterface AnimationKeyframe {\n  time: number; // in ms, relative to the start of the audio\n  shapes: Record<string, number>; // ARKit blendshape values\n}\n\n// Define ChatMessage structure\ninterface ChatMessage {\n  id: string;\n  text: string;\n  sender: 'user' | 'bot';\n  timestamp: Timestamp | Date; // Allow both Firebase Timestamp and JS Date\n  emotion?: string;\n}\n\n// Define Simulation data structure (placeholder, adjust as needed)\ninterface Simulation {\n  id: string;\n  name?: string;\n  description?: string;\n  avatarUrl?: string; // Assuming simulation might also define an avatar\n  // Add other fields as necessary based on your Firestore structure\n}\n\n// Interface for methods exposed by SimulationViewInternal via ref\nexport interface SimulationViewInternalHandle {\n  forceStopHumeSpeaking: () => void;\n}\n\n// State for the SimulationViewInternal component\ninterface SimulationViewState {\n  isMicOn: boolean;\n  isCameraOn: boolean;\n  isSoundOn: boolean;\n  isChatOpen: boolean;\n  messages: ChatMessage[];\n  inputValue: string;\n  isSpeaking: boolean;\n  isAzureAudioActive: boolean; // New: Tracks if Azure audio is playing\n  currentHumeEmotions: Emotion[]; // Stores the full array of emotions from Hume\n  statusMessage: string;\n  humeSessionId?: string;\n  humeAccessToken?: string;\n  humeVoiceId?: string;\n  humeVoiceName?: string;\n  humeConfigId?: string;\n  azureVoiceName?: string; \n  currentVisemeShapes: Partial<BlendShapeMap>; // Use Partial to allow omitting blink shapes for idle\n  simulationId?: string; // Added to store the simulation ID from URL\n  simulationData?: Simulation | null; // Added to store fetched simulation data\n  error?: string | null; // Added for error handling\n  isSending: boolean; // Tracks if a message is currently being sent via text input\n  manualBlendshapes: Partial<BlendShapeMap>; // For direct blendshape control via sliders\n  // Re-add properties that were removed but are used by UI\n  avatarUrl: string;\n  isCameraEnabled: boolean;\n  isMicMuted: boolean;\n  showChat: boolean;\n  currentProsodyBlendshapes: Partial<BlendShapeMap>;\n}\n\ninterface SimulationViewProps {\n  simulationId?: string; \n  avatarModelUrl: string; \n  // Add any other props that SimulationView might pass down\n}\n\n// Define types for props passed from SimulationView (parent) to SimulationViewInternal\n// Placeholder types are used; replace with actual types from useVoice or Hume SDK if available\ninterface SimulationViewInternalPassedProps {\n  // Props related to useVoice() have been moved into SimulationViewInternal,\n  // as useVoice() must be called by a descendant of VoiceProvider.\n  humeConfigId?: string; // Retained as SimulationViewInternal uses it for non-voice logic (e.g., fetching simulation data)\n}\n\n// Combined props for SimulationViewInternal\ntype SimulationViewInternalFullProps = SimulationViewProps & SimulationViewInternalPassedProps;\n\nconst ALL_TALK_ANIMATION_GLBS = [\n  \"/animations/M_Talking_Variations_001.glb\",\n  \"/animations/M_Talking_Variations_002.glb\",\n  \"/animations/M_Talking_Variations_003.glb\",\n  \"/animations/M_Talking_Variations_004.glb\",\n  \"/animations/M_Talking_Variations_005.glb\",\n  \"/animations/M_Talking_Variations_006.glb\",\n  \"/animations/M_Talking_Variations_007.glb\",\n  \"/animations/M_Talking_Variations_008.glb\",\n  \"/animations/M_Talking_Variations_009.glb\",\n  \"/animations/M_Talking_Variations_010.glb\",\n  \"/animations/talk.glb\"\n];\n\nconst ALL_IDLE_ANIMATION_GLBS = [\n  \"/animations/M_Standing_Idle_001.glb\",\n  \"/animations/M_Standing_Idle_002.glb\",\n  \"/animations/M_Standing_Idle_Variations_001.glb\",\n  \"/animations/M_Standing_Idle_Variations_002.glb\",\n  \"/animations/M_Standing_Idle_Variations_003.glb\",\n  \"/animations/M_Standing_Idle_Variations_004.glb\",\n  \"/animations/M_Standing_Idle_Variations_005.glb\",\n  \"/animations/M_Standing_Idle_Variations_006.glb\",\n  \"/animations/M_Standing_Idle_Variations_007.glb\",\n  \"/animations/M_Standing_Idle_Variations_008.glb\",\n  \"/animations/M_Standing_Idle_Variations_009.glb\",\n  \"/animations/M_Standing_Idle_Variations_010.glb\",\n  \"/animations/idle.glb\"\n];\n\nconst DEBOUNCE_DURATION = 250; // milliseconds\n\n// Helper function for button styles (to avoid repetition)\nconst buttonStyle: React.CSSProperties = {\n  background: 'rgba(0,0,0,0.5)',\n  border: '1px solid white',\n  borderRadius: '5px',\n  padding: '8px 12px',\n  color: 'white',\n  cursor: 'pointer',\n  fontSize: '0.9em',\n  margin: '5px',\n};\n\nconst SimulationViewInternal = React.forwardRef<\n  SimulationViewInternalHandle,\n  SimulationViewInternalFullProps\n>((props, ref) => {\n  // --- State and Refs ---\n  const [state, setState] = useState<SimulationViewState>(() => ({\n    isMicOn: false,\n    isCameraOn: true,\n    isSoundOn: true,\n    isChatOpen: false,\n    messages: [],\n    inputValue: '',\n    isSpeaking: false,\n    isAzureAudioActive: false,\n    currentHumeEmotions: [],\n    statusMessage: 'Initializing...',\n    humeVoiceName: 'KARL',\n    azureVoiceName: 'en-US-AvaNeural',\n    currentVisemeShapes: {},\n    manualBlendshapes: {},\n    simulationId: props.simulationId, // Initialize from props\n    simulationData: null,\n    error: null,\n    isSending: false,\n    avatarUrl: props.avatarModelUrl || '/bro.glb',\n    isCameraEnabled: true,\n    isMicMuted: false,\n    showChat: true,\n    currentProsodyBlendshapes: {},\n  }));\n  // Call useVoice() here, within the VoiceProvider's context provided by the parent SimulationView\n  const {\n    messages: humeMessages,\n    sendUserInput: sendUserInputToVoice,\n    readyState: voiceReadyState,\n    isPlaying: isHumeVoicePlaying,\n    disconnect: disconnectVoice,\n    connect: connectVoice,\n    status, // For logging or UI status display if needed\n  } = useVoice();\n\n  const avatarGroupRef = useRef<any>(null);\n  const messagesEndRef = useRef<HTMLDivElement>(null);\n  const azureAudioRef = useRef<HTMLAudioElement>(null);\n\n  // useEffect to fetch simulation data based on state.simulationId\n  useEffect(() => {\n    if (state.simulationId) {\n      console.log(`[SimulationViewInternal] useEffect: state.simulationId is: ${state.simulationId}. Fetching data.`);\n      const fetchSimulationData = async () => {\n        const db = getFirestore();\n        const simDocRef = doc(db, 'simulations', state.simulationId!);\n        try {\n          const docSnap = await getDoc(simDocRef);\n          if (docSnap.exists()) {\n            const fetchedData = docSnap.data() as Simulation;\n            console.log('[SimulationViewInternal] Fetched simulation data:', fetchedData);\n            setState(prev => ({\n              ...prev,\n              simulationData: fetchedData,\n              // Optionally set avatarUrl from simulationData if it exists and should override default\n              avatarUrl: fetchedData.avatarUrl || prev.avatarUrl,\n              error: null,\n            }));\n          } else {\n            console.error(\"[SimulationViewInternal] No such simulation document! ID:\", state.simulationId);\n            setState(prev => ({ ...prev, error: 'Simulation not found.', simulationData: null }));\n          }\n        } catch (err) {\n          console.error(\"[SimulationViewInternal] Error fetching simulation document:\", err);\n          setState(prev => ({ ...prev, error: 'Failed to fetch simulation data.', simulationData: null }));\n        }\n      };\n      fetchSimulationData();\n    } else {\n      console.log('[SimulationViewInternal] useEffect: state.simulationId is undefined. Clearing simulation data.');\n      // No need to set error here if it's an expected state (e.g. no ID provided initially)\n      setState(prev => ({ ...prev, simulationData: null, avatarUrl: props.avatarModelUrl || '/bro.glb' })); // Reset avatarUrl to default if no simId\n    }\n  }, [state.simulationId, props.avatarModelUrl]); // Depend on state.simulationId and props.avatarModelUrl for default\n\n  // --- Handlers and helpers ---\n  const handleAvatarErrorCb = useCallback((err: any) => {\n    setState(prev => ({ ...prev, error: 'Avatar error: ' + (err?.message || err) }));\n  }, []);\n  const handleAvatarLoadCb = useCallback(() => {\n    /* Optionally set state or fire analytics */\n  }, []);\n  const generateAndAnimateVisemesFromText = useCallback((text: string, voice: string) => {\n    // Placeholder: implement viseme generation logic\n    setState(prev => ({ ...prev, statusMessage: `Viseme test triggered for \"${text}\"` }));\n  }, []);\n  const handleSendMessage = useCallback((e: React.FormEvent<HTMLFormElement>) => {\n    e.preventDefault();\n    // Placeholder: implement send message logic\n    setState(prev => ({ ...prev, statusMessage: 'Message sent!' }));\n  }, []);\n  const handleInputChange = useCallback((e: React.ChangeEvent<HTMLInputElement>) => {\n    setState(prev => ({ ...prev, inputValue: e.target.value }));\n  }, []);\n  const toggleChat = useCallback(() => {\n    setState(prev => ({ ...prev, showChat: !prev.showChat }));\n  }, []);\n  const toggleMic = useCallback(() => {\n    setState(prev => ({ ...prev, isMicMuted: !prev.isMicMuted }));\n  }, []);\n  const toggleSound = useCallback(() => {\n    setState(prev => ({ ...prev, isSoundOn: !prev.isSoundOn }));\n  }, []);\n  const forceStopAllAudio = useCallback(() => {\n    setState(prev => ({ ...prev, isSpeaking: false, isAzureAudioActive: false }));\n  }, []);\n  const handleAzureAudioEnded = useCallback(() => {\n    setState(prev => ({ ...prev, isAzureAudioActive: false }));\n  }, []);\n  const handleAzureAudioError = useCallback(() => {\n    setState(prev => ({ ...prev, error: 'Azure audio error' }));\n  }, []);\n\n  // --- Derived values ---\n  const derivedIsSpeaking = state.isSpeaking || state.isAzureAudioActive || isHumeVoicePlaying;\n\n  // --- Render ---\n  console.log('Rendering avatar with URL:', state.avatarUrl);\n  return (\n    <div style={{ display: 'flex', flexDirection: 'row', height: '100%', position: 'relative' }}>\n      {/* Avatar and controls */}\n      <EmotionDrivenAvatar\n        key={state.avatarUrl}\n        ref={avatarGroupRef}\n        avatarUrl={state.avatarUrl}\n        isSpeaking={derivedIsSpeaking}\n        detectedEmotions={state.currentHumeEmotions}\n        visemeData={state.currentVisemeShapes}\n        directBlendshapes={state.currentProsodyBlendshapes}\n        cameraEnabled={state.isCameraEnabled}\n        talkAnimationPaths={ALL_TALK_ANIMATION_GLBS}\n        idleAnimationPaths={ALL_IDLE_ANIMATION_GLBS}\n        onError={handleAvatarErrorCb}\n        onLoad={handleAvatarLoadCb}\n      />\n      <button\n        onClick={() => generateAndAnimateVisemesFromText(\"Hello world, this is a test.\", state.azureVoiceName || \"en-US-JennyNeural\")}\n        style={{ ...buttonStyle, position: 'absolute', top: '10px', left: '10px', zIndex: 10 }}\n      >\n        Test Visemes\n      </button>\n      {/* Chat UI Area */}\n      {state.showChat && (\n        <div className=\"chat-ui\" style={{\n          width: '350px',\n          minWidth: '300px',\n          background: 'rgba(30, 33, 40, 0.95)',\n          color: 'white',\n          display: 'flex',\n          flexDirection: 'column',\n          padding: '15px',\n          borderLeft: '1px solid #4f5461',\n          boxSizing: 'border-box',\n          position: 'absolute',\n          right: 0,\n          top: 0,\n          bottom: 0,\n          zIndex: 5,\n          transition: 'transform 0.3s ease-in-out',\n          transform: 'translateX(0%)'\n        }}>\n          <div className=\"messages-area\" style={{ flexGrow: 1, overflowY: 'auto', marginBottom: '15px', paddingRight: '10px' }}>\n            {state.messages.map((msg) => (\n              <div key={msg.id} className={`message ${msg.sender}`} style={{\n                marginBottom: '12px',\n                padding: '10px 15px',\n                borderRadius: '18px',\n                maxWidth: '85%',\n                alignSelf: msg.sender === 'user' ? 'flex-end' : 'flex-start',\n                background: msg.sender === 'user' ? '#007bff' : '#495057',\n                color: 'white',\n                boxShadow: '0 2px 8px rgba(0,0,0,0.08)',\n                wordWrap: 'break-word',\n                fontSize: '0.95em'\n              }}>\n                {msg.text}\n                {msg.emotion && <em style={{ fontSize: '0.8em', display: 'block', opacity: 0.7, marginTop: '4px' }}>({msg.emotion})</em>}\n              </div>\n            ))}\n            <div ref={messagesEndRef} />\n          </div>\n          <audio\n            ref={azureAudioRef}\n            onEnded={handleAzureAudioEnded}\n            onError={handleAzureAudioError}\n            style={{ display: 'none' }}\n          />\n          <form onSubmit={handleSendMessage} style={{ display: 'flex', marginTop: 'auto', paddingTop: '10px', borderTop: '1px solid #4f5461', flexShrink: 0 }}>\n            <input\n              type=\"text\"\n              placeholder=\"Type your message...\"\n              value={state.inputValue}\n              onChange={handleInputChange}\n              style={{ flex: 1, padding: '10px', borderRadius: '8px', border: 'none', outline: 'none', marginRight: '8px', background: '#343a40', color: 'white' }}\n            />\n            <button type=\"submit\" style={{ ...buttonStyle, background: '#007bff', margin: 0 }}>\n              <FaPaperPlane />\n            </button>\n          </form>\n        </div>\n      )}\n      {/* Toggle Chat Button */}\n      {!state.showChat && (\n        <button\n          onClick={toggleChat}\n          style={{\n            position: 'absolute',\n            bottom: '30px',\n            right: '30px',\n            background: '#007bff',\n            color: 'white',\n            border: 'none',\n            borderRadius: '50%',\n            width: '60px',\n            height: '60px',\n            display: 'flex',\n            alignItems: 'center',\n            justifyContent: 'center',\n            cursor: 'pointer',\n            boxShadow: '0 4px 12px rgba(0,0,0,0.3)',\n            zIndex: 10,\n            transition: 'transform 0.2s ease'\n          }}\n          onMouseOver={e => (e.currentTarget.style.transform = 'scale(1.1)')}\n          onMouseOut={e => (e.currentTarget.style.transform = 'scale(1)')}\n        >\n          Chat\n        </button>\n      )}\n      {/* Controls Bar at the bottom */}\n      <div className=\"controls-bar\" style={{\n        display: 'flex',\n        justifyContent: 'center',\n        alignItems: 'center',\n        padding: '10px',\n        background: '#20232a',\n        flexShrink: 0,\n        gap: '10px'\n      }}>\n        <button onClick={toggleMic} style={buttonStyle} title={state.isMicMuted ? 'Unmute Microphone' : 'Mute Microphone'}>\n          {state.isMicMuted ? <FaMicrophoneSlash /> : <FaMicrophone />} {state.isMicMuted ? 'Mic Off' : 'Mic On'}\n        </button>\n        <button onClick={toggleSound} style={buttonStyle} title={state.isSoundOn ? 'Mute Sound' : 'Unmute Sound'}>\n          {state.isSoundOn ? <FaVolumeUp /> : <FaVolumeMute />} {state.isSoundOn ? 'Sound On' : 'Sound Off'}\n        </button>\n        <button onClick={forceStopAllAudio} style={{...buttonStyle, background: '#dc3545'}} title=\"Force stop all audio and speech\">\n          <FaStopCircle /> Stop All Audio\n        </button>\n      </div>\n    </div>\n  );\n});\n\nexport const SimulationView: React.FC<SimulationViewProps> = (props) => {\n  const [humeAudioIndicatorMessage, setHumeAudioIndicatorMessage] = useState<string>('Hume Audio: Idle');\n  const internalCompRef = useRef<SimulationViewInternalHandle>(null);\n  const humeApiKey = React.useMemo(() => {\n    const key = process.env.REACT_APP_HUME_API_KEY;\n    if (!key) {\n      console.error(\"CRITICAL: REACT_APP_HUME_API_KEY is not set. Hume EVI will not work.\");\n    }\n    return key || '';\n  }, []);\n\n  const humeConfigId = '9c6f9d9b-1699-41bb-b335-9925bba5d6d9'; // Temporarily hardcoded for testing\n\n  // The useVoice() hook and related logs have been moved to SimulationViewInternal.\n  // This is because useVoice() must be called by a component that is a descendant of VoiceProvider.\n\n  const handleVoiceOpen = useCallback(() => {\n    console.log('[Hume EVI] Connection opened via VoiceProvider.');\n  }, []);\n\n  const voiceAuth = useMemo(() => ({\n    type: 'apiKey' as const,\n    value: humeApiKey,\n  }), [humeApiKey]);\n\n  const handleVoiceMessage = useCallback((message: JSONMessage) => {\n    const messageType = message.type;\n    // Update based on Hume EVI messages from local useVoice() hook\n    console.log(`[Hume EVI] Message received - Type: ${messageType}`);\n\n    switch (messageType) {\n      case 'assistant_message':\n        console.log('[Hume EVI] Assistant Message details:', message); // Log the full assistant_message object\n        if (message.models) {\n          const modelsAsAny = message.models as any; // Cast to any for easier access to dynamic model structure\n          if (modelsAsAny.face && modelsAsAny.face.predictions) {\n            // Log only if face predictions are present\n            console.log('[Hume EVI] Face model predictions:', modelsAsAny.face.predictions);\n          }\n          // Optional: Log if models exist but face/predictions are missing for debugging model structure\n          // else {\n          //   console.log('[Hume EVI] message.models.face or .predictions not found. message.models structure:', message.models);\n          // }\n        }\n        break;\n      case 'user_interruption':\n        console.log('[Hume EVI] User Interruption details:', message);\n        break;\n      case 'tool_call':\n        console.log('[Hume EVI] Tool Call details:', message);\n        break;\n      case 'tool_response':\n        console.log('[Hume EVI] Tool Response details:', message);\n        break;\n      case 'tool_error':\n        console.error('[Hume EVI] Tool Error details:', message);\n        break;\n      // Add cases for other specific message types if they become important for debugging\n      default:\n        // For any other message types, only their type is logged by the initial console.log.\n        // This significantly reduces noise from less critical or very frequent messages.\n        // If deeper debugging for other types is needed, uncomment the line below:\n        // console.log(`[Hume EVI] Other message type '${messageType}', content:`, message);\n        break;\n    }\n  }, []);\n\n  const handleVoiceClose = useCallback((e: any) => {\n    console.log('[Hume EVI] Connection closed via VoiceProvider. Code:', e.code, 'Reason:', e.reason, 'WasClean:', e.wasClean);\n    internalCompRef.current?.forceStopHumeSpeaking();\n  }, []);\n\n  const handleVoiceError = useCallback((error: any) => {\n    let logMessage = `[Hume EVI] VoiceProvider error - Type: ${error.type}, Code: ${error.code}, Message: ${error.message}`;\n    console.error(logMessage, error);\n  }, []);\n\n  if (!humeApiKey) {\n     console.warn(\"[SimulationView] Hume API Key is not available. VoiceProvider will likely fail to connect.\");\n     // Optionally, render a message to the user or a disabled state for the component\n     // return <div>Hume API Key is missing. Please configure REACT_APP_HUME_API_KEY in your environment.</div>;\n  }\n\n  console.log(`[SimulationView] Attempting to connect VoiceProvider with API Key: \"${humeApiKey}\" and Config ID: \"${humeConfigId}\"`);\n  console.log(`[SimulationView] voiceAuth object being passed:`, voiceAuth);\n\n  return (\n    <>\n      <div style={{ padding: '8px', backgroundColor: '#ff69b4', color: 'white', textAlign: 'center', fontWeight: 'bold', fontSize: '1.1em', zIndex: 9999, position: 'relative' }}>\n        HUME AUDIO EVENT STATUS: {humeAudioIndicatorMessage}\n      </div>\n      <VoiceProvider\n      onAudioStart={() => {\n        console.log('[Hume EVI VoiceProvider] onAudioStart triggered');\n        setHumeAudioIndicatorMessage('Hume Audio: STARTED');\n      }}\n      onAudioEnd={() => {\n        console.log('[Hume EVI VoiceProvider] onAudioEnd triggered');\n        setHumeAudioIndicatorMessage('Hume Audio: ENDED');\n      }}\n      auth={voiceAuth}\n      configId={humeConfigId}\n      debug={true}\n      onOpen={handleVoiceOpen}\n      onMessage={handleVoiceMessage}\n      onClose={handleVoiceClose}\n      onError={handleVoiceError}\n    >\n      <SimulationViewInternal\n          ref={internalCompRef}\n          avatarModelUrl={props.avatarModelUrl}\n          simulationId={props.simulationId} // Restore simulationId prop\n          // Props from the outer useVoice() call are removed.\n          // SimulationViewInternal will now call useVoice() itself.\n          humeConfigId={humeConfigId} // Pass the configId down, if still needed by SimulationViewInternal for non-voice logic\n        />\n    </VoiceProvider>\n    </>\n  );\n};\n\n\n"],"names":["ARKitBlendshapeNamesList","reduce","acc","key","ALL_TALK_ANIMATION_GLBS","ALL_IDLE_ANIMATION_GLBS","buttonStyle","background","border","borderRadius","padding","color","cursor","fontSize","margin","SimulationViewInternal","React","props","ref","state","setState","useState","isMicOn","isCameraOn","isSoundOn","isChatOpen","messages","inputValue","isSpeaking","isAzureAudioActive","currentHumeEmotions","statusMessage","humeVoiceName","azureVoiceName","currentVisemeShapes","manualBlendshapes","simulationId","simulationData","error","isSending","avatarUrl","avatarModelUrl","isCameraEnabled","isMicMuted","showChat","currentProsodyBlendshapes","humeMessages","sendUserInput","sendUserInputToVoice","readyState","voiceReadyState","isPlaying","isHumeVoicePlaying","disconnect","disconnectVoice","connect","connectVoice","status","useVoice","avatarGroupRef","useRef","messagesEndRef","azureAudioRef","useEffect","console","log","concat","async","db","getFirestore","simDocRef","doc","docSnap","getDoc","exists","fetchedData","data","prev","_objectSpread","err","fetchSimulationData","handleAvatarErrorCb","useCallback","message","handleAvatarLoadCb","generateAndAnimateVisemesFromText","text","voice","handleSendMessage","e","preventDefault","handleInputChange","target","value","toggleChat","toggleMic","toggleSound","forceStopAllAudio","handleAzureAudioEnded","handleAzureAudioError","derivedIsSpeaking","_jsxs","style","display","flexDirection","height","position","children","_jsx","EmotionDrivenAvatar","detectedEmotions","visemeData","directBlendshapes","cameraEnabled","talkAnimationPaths","idleAnimationPaths","onError","onLoad","onClick","top","left","zIndex","className","width","minWidth","borderLeft","boxSizing","right","bottom","transition","transform","flexGrow","overflowY","marginBottom","paddingRight","map","msg","sender","maxWidth","alignSelf","boxShadow","wordWrap","emotion","opacity","marginTop","id","onEnded","onSubmit","paddingTop","borderTop","flexShrink","type","placeholder","onChange","flex","outline","marginRight","FaPaperPlane","alignItems","justifyContent","onMouseOver","currentTarget","onMouseOut","gap","title","FaMicrophoneSlash","FaMicrophone","FaVolumeUp","FaVolumeMute","FaStopCircle","SimulationView","humeAudioIndicatorMessage","setHumeAudioIndicatorMessage","internalCompRef","humeApiKey","process","humeConfigId","handleVoiceOpen","voiceAuth","useMemo","handleVoiceMessage","messageType","models","modelsAsAny","face","predictions","handleVoiceClose","_internalCompRef$curr","code","reason","wasClean","current","forceStopHumeSpeaking","handleVoiceError","logMessage","warn","_Fragment","backgroundColor","textAlign","fontWeight","VoiceProvider","onAudioStart","onAudioEnd","auth","configId","debug","onOpen","onMessage","onClose"],"sourceRoot":""}