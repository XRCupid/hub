{"version":3,"file":"static/js/3855.dfc789df.chunk.js","mappings":"qRAiBA,MA8cA,EA9c+BA,KAC7B,MAAM,QAAEC,EAAU,UAAYC,EAAAA,EAAAA,KACxBC,GAAWC,EAAAA,EAAAA,MAGXC,GAAQC,EAAAA,EAAAA,IAAaL,IAIpBM,EAAaC,KAHDC,EAAAA,EAAAA,IAAmBR,IAGAS,EAAAA,EAAAA,WAAS,KACxCC,EAAgBC,IAAqBF,EAAAA,EAAAA,UAAyB,CAAC,IAC/DG,EAAWC,IAAgBJ,EAAAA,EAAAA,UAAqB,IAAIK,WAAW,OAC/DC,EAAcC,IAAmBP,EAAAA,EAAAA,UAAS,KAC1CQ,EAAgBC,IAAqBT,EAAAA,EAAAA,UAAS,KAC9CU,EAASC,IAAcX,EAAAA,EAAAA,WAAS,IAChCY,EAAOC,IAAYb,EAAAA,EAAAA,UAAwB,OAC3Cc,EAAkBC,IAAuBf,EAAAA,EAAAA,UAAc,OACvDgB,EAAcC,IAAmBjB,EAAAA,EAAAA,UAAS,KAC1CkB,EAAcC,IAAmBnB,EAAAA,EAAAA,UAA6B,OAC9DoB,EAAgBC,IAAqBrB,EAAAA,EAAAA,WAAS,IAC9CsB,EAAkBC,IAAuBvB,EAAAA,EAAAA,UAAiB,SAC1DwB,EAAsBC,IAA2BzB,EAAAA,EAAAA,UAAc,CAAC,IAChE0B,EAAYC,IAAiB3B,EAAAA,EAAAA,WAAS,IACtC4B,EAAaC,IAAkB7B,EAAAA,EAAAA,WAAS,IACxC8B,EAAUC,IAAe/B,EAAAA,EAAAA,UAAmD,KAC5EgC,EAA+BC,IAAoCjC,EAAAA,EAAAA,WAAS,GAG7EkC,GAAsBC,EAAAA,EAAAA,QAAkC,MAGxDC,GAAkBD,EAAAA,EAAAA,QAA4B,MAC9CE,GAAcF,EAAAA,EAAAA,QAA4B,MAC1CG,GAAiBH,EAAAA,EAAAA,QAAyB,IAAII,OAC9CC,IAAgBL,EAAAA,EAAAA,QAAe,IAC/BM,IAAeN,EAAAA,EAAAA,SAAO,GACtBO,IAAwBP,EAAAA,EAAAA,SAAO,IAGrCQ,EAAAA,EAAAA,YAAU,KAERL,EAAeM,QAAQC,QAAU,KAC/BC,QAAQC,IAAI,4CACZpB,GAAc,GACdJ,EAAoB,QACpBuB,QAAQC,IAAI,+CACZC,YAAW,IAAMC,MAA0B,MAGtC,KACDb,EAAgBQ,SAA6C,WAAlCR,EAAgBQ,QAAQM,OACrDd,EAAgBQ,QAAQO,WAG3B,KAGHR,EAAAA,EAAAA,YAAU,KACoBS,WAC1B,IACEN,QAAQC,IAAI,kEACZ,MAAMM,QAAeC,UAAUC,aAAaC,aAAa,CACvDC,OAAO,EACPC,OAAO,IAITL,EAAOM,iBAAiBC,SAAQC,IAC9BA,EAAMC,iBAAiB,SAAS,KAC9BhB,QAAQC,IAAI,0CAGhB5B,EAAgBkC,GAChBhC,GAAkB,EACpB,CAAE,MAAOT,GACPkC,QAAQlC,MAAM,gDAAiDA,GAC/DC,EAAS,kEACX,GAGFkD,GAEO,KACD7C,GACFA,EAAa8C,YAAYJ,SAAQC,GAASA,EAAMI,YAGnD,KAGHtB,EAAAA,EAAAA,YAAU,KACuBS,WACxBlB,EAAoBU,UACvBE,QAAQC,IAAI,qDACZb,EAAoBU,QAAU,IAAIsB,EAAAA,EAGlChC,EAAoBU,QAAQuB,SAASC,IACnCtB,QAAQC,IAAI,iCAAkCqB,EAAUC,MACxD1C,GAAc,GACdJ,EAAoB,WACpBuB,QAAQC,IAAI,kDACZP,GAAcI,QAAQ0B,KAAKF,GACtB3B,GAAaG,SAChBK,QAIJf,EAAoBU,QAAQ2B,WAAWC,IAAkB,IAADC,EACtD3B,QAAQC,IAAI,mCAAoCyB,GAChD,MAAME,EAAiC,kBAAZF,EAAuBA,GACxB,OAAPA,QAAO,IAAPA,GAAgB,QAATC,EAAPD,EAASA,eAAO,IAAAC,OAAT,EAAPA,EAAkBE,WAAkB,OAAPH,QAAO,IAAPA,OAAO,EAAPA,EAASG,UACtCC,KAAKC,UAAUL,GAEM,IAADM,EAAAC,EAAvC,GAAIL,GAAeA,EAAYM,SAC7BjD,GAAYkD,GAAQ,IAAIA,EAAM,CAC5BC,KAAM,YACNP,QAASD,MAEXnE,EAAgBmE,GAGL,OAAPF,QAAO,IAAPA,GAAe,QAARM,EAAPN,EAASW,cAAM,IAAAL,GAAS,QAATC,EAAfD,EAAiBM,eAAO,IAAAL,GAAxBA,EAA0BM,QAAQ,CACpC,MAAMA,EAASb,EAAQW,OAAOC,QAAQC,OAEhCC,EAAgBC,OAAOC,QAAQH,GAAQI,KAAIC,IAAA,IAAEC,EAAMC,GAAMF,EAAA,MAAM,CACnEC,KAAMA,EAAKE,OAAO,GAAGC,cAAgBH,EAAKI,MAAM,GAChDH,MAAOA,MAEHI,GAAcC,EAAAA,EAAAA,GAAyBX,GAC7C7D,EAAwBuE,EAC1B,KAIJ9D,EAAoBU,QAAQsD,gBAAe,KACzCpD,QAAQC,IAAI,kCACZpB,GAAc,GACdJ,EAAoB,QACpBuB,QAAQC,IAAI,kDAGdb,EAAoBU,QAAQuD,eAAeC,IACzCtD,QAAQC,IAAI,+BAAgCqD,GAC5CrE,GAAYkD,GAAQ,IAAIA,EAAM,CAC5BC,KAAM,OACNP,QAASyB,MAEX3F,EAAkB2F,MAGpBlE,EAAoBU,QAAQyD,SAASzF,IACnCkC,QAAQlC,MAAM,wBAAyBA,GACvCC,EAASD,EAAM4D,YAGjB1B,QAAQC,IAAI,gEAIhBuD,KACC,IAGH,MAqDMrD,GAAyBA,KAC7B,GAAqC,IAAjCT,GAAcI,QAAQ2D,OAKxB,OAJA9D,GAAaG,SAAU,EACvBjB,GAAc,GACdJ,EAAoB,aACpBuB,QAAQC,IAAI,+CAIdD,QAAQC,IAAI,yDAA0DP,GAAcI,QAAQ2D,QAC5F9D,GAAaG,SAAU,EACvB,MAAMwB,EAAY5B,GAAcI,QAAQ4D,QAClCC,EAAWC,IAAIC,gBAAgBvC,GAIrC,GAHA9B,EAAeM,QAAQgE,IAAMH,GAGxB/D,GAAsBE,QACzB,IACE,IAAKR,EAAgBQ,SAA6C,WAAlCR,EAAgBQ,QAAQM,MAAoB,CAC1E,MAAM2D,EAAeC,OAAOD,cAAiBC,OAAeC,mBAC5D3E,EAAgBQ,QAAU,IAAIiE,EAAa,CAAEG,WAAY,OACzDlE,QAAQC,IAAI,0CACd,CAEsC,cAAlCX,EAAgBQ,QAAQM,QAC1Bd,EAAgBQ,QAAQqE,SACxBnE,QAAQC,IAAI,wCAGd,MAAMmE,EAAW9E,EAAgBQ,QAAQuE,iBACzCD,EAASE,QAAU,IACJhF,EAAgBQ,QAAQyE,yBAAyB/E,EAAeM,SACxE0E,QAAQJ,GACfA,EAASI,QAAQlF,EAAgBQ,QAAQ2E,aAEzClF,EAAYO,QAAUsE,EACtBxE,GAAsBE,SAAU,EAChCE,QAAQC,IAAI,+CACd,CAAE,MAAOnC,GACPkC,QAAQlC,MAAM,kDAAmDA,EACnE,CAGF0B,EAAeM,QAAQ4E,OACpBC,MAAK,KACJ3E,QAAQC,IAAI,6CACZpB,GAAc,GACdJ,EAAoB,WACpBuB,QAAQC,IAAI,qDAEb2E,OAAMC,IACL7E,QAAQlC,MAAM,sCAAuC+G,GACrDlF,GAAaG,SAAU,EACvBjB,GAAc,GACdJ,EAAoB,QACpBuB,QAAQC,IAAI,+CACZC,YAAW,IAAMC,MAA0B,QAG/CX,EAAeM,QAAQC,QAAU,KAC/BC,QAAQC,IAAI,uCACZ2D,IAAIkB,gBAAgBnB,GACpBhE,GAAaG,SAAU,EACvBjB,GAAc,GACdJ,EAAoB,QACpBuB,QAAQC,IAAI,+CAEZC,YAAW,IAAMC,MAA0B,QAK/CN,EAAAA,EAAAA,YAAU,KACR,IAAKjB,IAAeW,EAAYO,QAE9B,YADAxC,EAAa,IAAIC,YAInByC,QAAQC,IAAI,uDACZ,MAAMmE,EAAW7E,EAAYO,QACvBiF,EAAeX,EAASY,kBACxBC,EAAY,IAAI1H,WAAWwH,GACjC,IAAIG,EACAC,EAAc,EAElB,MAAMC,EAAkBA,KACtBhB,EAASiB,qBAAqBJ,GAC9B3H,EAAa,IAAIC,WAAW0H,IAG5B,MAAMK,EAAMC,KAAKD,MACjB,GAAIA,EAAMH,EAAc,IAAM,CAC5B,MAAMK,EAAWP,EAAUQ,QAAO,CAACC,EAAKC,IAAQD,EAAMC,GAAK,GAAKV,EAAUxB,OAC1EzD,QAAQC,IAAI,6CAA8CuF,EAASI,QAAQ,GAAI,OAAQC,KAAKC,OAAOb,IACnGE,EAAcG,CAChB,CAEAJ,EAAca,sBAAsBX,IAKtC,OAFAA,IAEO,KACDF,GACFc,qBAAqBd,GAEvBlF,QAAQC,IAAI,uDACZ3C,EAAa,IAAIC,eAElB,CAACqB,IAwBJ,OARAiB,EAAAA,EAAAA,YAAU,KACR,MAAMoG,GAAcC,EAAAA,EAAAA,MACfD,EAAYE,QAAWF,EAAYG,YACtCjH,GAAiC,GACjCpB,EAAS,kFAEV,KAGDsI,EAAAA,EAAAA,MAAA,OAAKC,UAAU,gBAAeC,SAAA,EAC5BC,EAAAA,EAAAA,KAACC,EAAAA,WAAU,KACXJ,EAAAA,EAAAA,MAAA,OAAKC,UAAU,eAAcC,SAAA,EAC3BF,EAAAA,EAAAA,MAAA,MAAAE,SAAA,CAAI,mBAAqB,OAAL1J,QAAK,IAALA,OAAK,EAALA,EAAOgG,OAAQ,oBACnC2D,EAAAA,EAAAA,KAAA,UAAQE,QAASA,IAAM/J,EAAS,YAAa2J,UAAU,cAAaC,SAAC,wBAKvEF,EAAAA,EAAAA,MAAA,OAAKC,UAAU,oBAAmBC,SAAA,CAC/BrH,IACCsH,EAAAA,EAAAA,KAACG,EAAAA,QAAyB,KAE5BN,EAAAA,EAAAA,MAAA,OAAKC,UAAU,qBAAqBM,MAAO,CACzCC,gBAAiB,UACjBC,gBAAsB,OAALjK,QAAK,IAALA,GAAAA,EAAOkK,MAAK,eAAAC,OAAkBnK,EAAMkK,MAAK,KAAM,OAChEE,eAAgB,QAChBC,mBAAoB,SACpBC,iBAAkB,aAClBZ,SAAA,CACCzH,IACCuH,EAAAA,EAAAA,MAACe,EAAAA,GAAM,CAACC,OAAQ,CAAEC,SAAU,CAAC,EAAG,GAAK,GAAIC,IAAK,IAAKhB,SAAA,EACjDC,EAAAA,EAAAA,KAAA,gBAAcgB,UAAW,MACzBhB,EAAAA,EAAAA,KAAA,oBAAkBc,SAAU,CAAC,EAAG,EAAG,GAAIE,UAAW,OAClDhB,EAAAA,EAAAA,KAACiB,EAAAA,SAAQ,CAACC,SAAU,KAAKnB,UACvBC,EAAAA,EAAAA,KAACmB,EAAAA,eAAc,CACbC,WAAgB,OAAL/K,QAAK,IAALA,OAAK,EAALA,EAAOgL,SAAU,2BAC5BP,SAAU,CAAC,GAAI,IAAK,GACpBQ,MAAO,IACPC,cAAevJ,EACfE,qBAAsBA,EACtBrB,UAAWA,UAKjByB,GAAejC,IACfwJ,EAAAA,EAAAA,MAAA,OAAKC,UAAU,gBAAgBM,MAAO,CACpCoB,QAAS,OACTC,cAAe,SACfC,WAAY,SACZC,eAAgB,SAChBC,OAAQ,OACRC,MAAO,QACPC,UAAW,SACXC,QAAS,QACThC,SAAA,EACAC,EAAAA,EAAAA,KAAA,MAAAD,SAAK1J,EAAMgG,QACX2D,EAAAA,EAAAA,KAAA,KAAAD,SAAI1J,EAAM2L,eACVhC,EAAAA,EAAAA,KAAA,KAAGI,MAAO,CAAE6B,UAAW,OAAQC,QAAS,IAAMnC,SAAC,gDAQpDoC,GAgBDtC,EAAAA,EAAAA,MAAA,OAAKC,UAAU,mBAAkBC,SAAA,CAC7BzH,GASA0H,EAAAA,EAAAA,KAAA,UACEE,QAvOapG,UACvB,IACMlB,EAAoBU,gBAChBV,EAAoBU,QAAQ8I,aAClC7J,GAAe,GACfE,EAAY,IAEhB,CAAE,MAAO4J,GACP7I,QAAQlC,MAAM,mCAAoC+K,EACpD,GA+NUvC,UAAU,4BAA2BC,SACtC,gCAXDC,EAAAA,EAAAA,KAAA,UACEE,QAvQUpG,UACpB,IAIE,GAHAzC,GAAW,GACXE,EAAS,MAELqB,EAAoBU,QAAS,CAC/B,MAAMgJ,GAAgB,OAALjM,QAAK,IAALA,OAAK,EAALA,EAAOkM,eAAgBJ,uCACxC3I,QAAQC,IAAI,sDACZb,EAAoBU,QAAQ0E,QAAQsE,GAAUnE,MAAK,KACjD3E,QAAQC,IAAI,oCACZlB,GAAe,GACflB,GAAW,GAGXqC,YAAW,KACTF,QAAQC,IAAI,wDACZxB,EAAoB,WACpBI,GAAc,GAGdqB,YAAW,KACTF,QAAQC,IAAI,0DACZxB,EAAoB,QACpBI,GAAc,KACb,OACF,QACF+F,OAAO9G,IACRkC,QAAQlC,MAAM,mCAAoCA,GAClDC,EAASD,aAAiBkL,MAAQlL,EAAM4D,QAAU,gCAEtD,CACF,CAAE,MAAOmH,GACP7I,QAAQlC,MAAM,mCAAoC+K,GAClD9K,EAAS8K,aAAeG,MAAQH,EAAInH,QAAU,6BAChD,CAAC,QACC7D,GAAW,EACb,GAoOUoL,UAAW3K,GAAkBV,EAC7B0I,UAAU,8BAA6BC,SAEtC3I,EAAU,gBAAkB,yBAUjCyI,EAAAA,EAAAA,MAAA,OAAKC,UAAU,oBAAmBC,SAAA,CAAC,WACxBzH,EAAc,6CAAqC,+BAMjER,GAAkBF,IACjBoI,EAAAA,EAAAA,KAAC0C,EAAAA,cAAa,CACZtB,UAAU,2BACVN,SAAS,eACT/F,KAAK,SACL4H,aAAcnL,EACdoL,mBAAmB,EACnBhL,aAAcA,O","sources":["components/DougieCoachCopy.tsx"],"sourcesContent":["import React, { useState, useEffect, useRef, Suspense } from 'react';\nimport { useParams, useNavigate } from 'react-router-dom';\nimport { Canvas } from '@react-three/fiber';\nimport { HybridVoiceService } from '../services/hybridVoiceService';\nimport { PresenceAvatar } from './PresenceAvatar';\nimport { getCoachById } from '../config/coachConfig';\nimport { getHumeCoachConfig } from '../services/HumeCoachConfigurations';\nimport { MediaDebug } from './MediaDebug';\nimport { UserAvatarPiP } from './UserAvatarPiP';\nimport { EmotionalState } from '../services/humeVoiceService';\nimport { COACHES } from '../config/coachConfig';\nimport { mapEmotionsToBlendshapes } from '../utils/emotionMappings';\nimport EmergencyCredentialsInput from './EmergencyCredentialsInput';\nimport { getHumeCredentials } from '../services/humeCredentialsOverride';\nimport './CoachSession.css';\n\n// Main component\nconst CoachSession: React.FC = () => {\n  const { coachId = 'grace' } = useParams<{ coachId: string }>();\n  const navigate = useNavigate();\n  \n  // Get coach data\n  const coach = getCoachById(coachId);\n  const humeConfig = getHumeCoachConfig(coachId);\n  \n  // State management\n  const [isListening, setIsListening] = useState(false);\n  const [currentEmotion, setCurrentEmotion] = useState<EmotionalState>({});\n  const [audioData, setAudioData] = useState<Uint8Array>(new Uint8Array(128));\n  const [coachMessage, setCoachMessage] = useState('');\n  const [userTranscript, setUserTranscript] = useState('');\n  const [loading, setLoading] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n  const [faceTrackingData, setFaceTrackingData] = useState<any>(null);\n  const [messageInput, setMessageInput] = useState('');\n  const [cameraStream, setCameraStream] = useState<MediaStream | null>(null);\n  const [hasPermissions, setHasPermissions] = useState(false);\n  const [currentAnimation, setCurrentAnimation] = useState<string>('idle');\n  const [emotionalBlendshapes, setEmotionalBlendshapes] = useState<any>({});\n  const [isSpeaking, setIsSpeaking] = useState(false);\n  const [isConnected, setIsConnected] = useState(false);\n  const [messages, setMessages] = useState<Array<{ role: string; content: string }>>([]);\n  const [showEmergencyCredentialsInput, setShowEmergencyCredentialsInput] = useState(false);\n  \n  // Service refs\n  const humeVoiceServiceRef = useRef<HybridVoiceService | null>(null);\n  \n  // Audio refs for lip sync\n  const audioContextRef = useRef<AudioContext | null>(null);\n  const analyserRef = useRef<AnalyserNode | null>(null);\n  const audioPlayerRef = useRef<HTMLAudioElement>(new Audio());\n  const audioQueueRef = useRef<Blob[]>([]);\n  const isPlayingRef = useRef(false);\n  const audioSourceCreatedRef = useRef(false);\n  \n  // Initialize audio context\n  useEffect(() => {\n    // Audio element setup\n    audioPlayerRef.current.onended = () => {\n      console.log('[CoachSession] Audio ended, playing next');\n      setIsSpeaking(false);\n      setCurrentAnimation('idle');\n      console.log('[CoachSession] Animation state set to: idle');\n      setTimeout(() => playNextAudioFromQueue(), 100);\n    };\n    \n    return () => {\n      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {\n        audioContextRef.current.close();\n      }\n    };\n  }, []);\n\n  // Get media permissions\n  useEffect(() => {\n    const getMediaPermissions = async () => {\n      try {\n        console.log('[CoachSession] Requesting camera and microphone permissions...');\n        const stream = await navigator.mediaDevices.getUserMedia({ \n          video: true, \n          audio: true \n        });\n        \n        // Set up face tracking\n        stream.getVideoTracks().forEach(track => {\n          track.addEventListener('ended', () => {\n            console.log('[CoachSession] Video track ended');\n          });\n        });\n        setCameraStream(stream);\n        setHasPermissions(true);\n      } catch (error) {\n        console.error('[CoachSession] Error accessing media devices:', error);\n        setError('Please allow camera and microphone access for the coach session');\n      }\n    };\n\n    getMediaPermissions();\n\n    return () => {\n      if (cameraStream) {\n        cameraStream.getTracks().forEach(track => track.stop());\n      }\n    };\n  }, []);\n\n  // Initialize HybridVoiceService\n  useEffect(() => {\n    const initHybridVoiceService = async () => {\n      if (!humeVoiceServiceRef.current) {\n        console.log('[CoachSession] Initializing HybridVoiceService...');\n        humeVoiceServiceRef.current = new HybridVoiceService();\n        \n        // Set up callbacks for audio and messages\n        humeVoiceServiceRef.current.onAudio((audioBlob: Blob) => {\n          console.log('[CoachSession] Audio received:', audioBlob.size);\n          setIsSpeaking(true);\n          setCurrentAnimation('talking');\n          console.log('[CoachSession] Animation state set to: talking');\n          audioQueueRef.current.push(audioBlob);\n          if (!isPlayingRef.current) {\n            playNextAudioFromQueue();\n          }\n        });\n        \n        humeVoiceServiceRef.current.onMessage((message: any) => {\n          console.log('[CoachSession] Message received:', message);\n          const messageText = typeof message === 'string' ? message : \n                            (message?.message?.content || message?.content || \n                             JSON.stringify(message));\n          \n          if (messageText && messageText.trim()) {\n            setMessages(prev => [...prev, {\n              role: 'assistant',\n              content: messageText\n            }]);\n            setCoachMessage(messageText);\n            \n            // Handle prosody for emotions\n            if (message?.models?.prosody?.scores) {\n              const scores = message.models.prosody.scores;\n              // Convert scores object to array format expected by mapEmotionsToBlendshapes\n              const emotionsArray = Object.entries(scores).map(([name, score]) => ({\n                name: name.charAt(0).toUpperCase() + name.slice(1), // Capitalize first letter\n                score: score as number\n              }));\n              const blendshapes = mapEmotionsToBlendshapes(emotionsArray);\n              setEmotionalBlendshapes(blendshapes);\n            }\n          }\n        });\n        \n        humeVoiceServiceRef.current.onAssistantEnd(() => {\n          console.log('[CoachSession] Assistant ended');\n          setIsSpeaking(false);\n          setCurrentAnimation('idle');\n          console.log('[CoachSession] Animation state set to: idle');\n        });\n        \n        humeVoiceServiceRef.current.onUserMessage((transcript: string) => {\n          console.log('[CoachSession] User message:', transcript);\n          setMessages(prev => [...prev, {\n            role: 'user',\n            content: transcript\n          }]);\n          setUserTranscript(transcript);\n        });\n        \n        humeVoiceServiceRef.current.onError((error: Error) => {\n          console.error('[CoachSession] Error:', error);\n          setError(error.message);\n        });\n        \n        console.log('[CoachSession] HybridVoiceService initialized successfully');\n      }\n    };\n    \n    initHybridVoiceService();\n  }, []);\n\n  // Handle connect\n  const handleConnect = async () => {\n    try {\n      setLoading(true);\n      setError(null);\n      \n      if (humeVoiceServiceRef.current) {\n        const configId = coach?.humeConfigId || process.env.REACT_APP_HUME_CONFIG_ID;\n        console.log('[CoachSession] Connecting to HybridVoiceService...');\n        humeVoiceServiceRef.current.connect(configId).then(() => {\n          console.log('[CoachSession] Connected to Hume');\n          setIsConnected(true);\n          setLoading(false);\n          \n          // TEMPORARY TEST: Force talking animation after 2 seconds to test lip sync\n          setTimeout(() => {\n            console.log('[CoachSession] TEST: Forcing talking animation state');\n            setCurrentAnimation('talking');\n            setIsSpeaking(true);\n            \n            // Reset after 5 seconds\n            setTimeout(() => {\n              console.log('[CoachSession] TEST: Resetting to idle animation state');\n              setCurrentAnimation('idle');\n              setIsSpeaking(false);\n            }, 5000);\n          }, 2000);\n        }).catch((error: any) => {\n          console.error('[CoachSession] Connection error:', error);\n          setError(error instanceof Error ? error.message : 'Failed to connect to coach');\n        });\n      }\n    } catch (err) {\n      console.error('[CoachSession] Connection error:', err);\n      setError(err instanceof Error ? err.message : 'Failed to connect to coach');\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  // Handle disconnect\n  const handleDisconnect = async () => {\n    try {\n      if (humeVoiceServiceRef.current) {\n        await humeVoiceServiceRef.current.disconnect();\n        setIsConnected(false);\n        setMessages([]);\n      }\n    } catch (err) {\n      console.error('[CoachSession] Disconnect error:', err);\n    }\n  };\n\n  // Play next audio from queue\n  const playNextAudioFromQueue = () => {\n    if (audioQueueRef.current.length === 0) {\n      isPlayingRef.current = false;\n      setIsSpeaking(false);\n      setCurrentAnimation('idle');\n      console.log('[CoachSession] Animation state set to: idle');\n      return;\n    }\n    \n    console.log('[CoachSession] Playing audio from queue, queue length:', audioQueueRef.current.length);\n    isPlayingRef.current = true;\n    const audioBlob = audioQueueRef.current.shift()!;\n    const audioUrl = URL.createObjectURL(audioBlob);\n    audioPlayerRef.current.src = audioUrl;\n    \n    // Setup audio analyzer for lip sync BEFORE playing\n    if (!audioSourceCreatedRef.current) {\n      try {\n        if (!audioContextRef.current || audioContextRef.current.state === 'closed') {\n          const AudioContext = window.AudioContext || (window as any).webkitAudioContext;\n          audioContextRef.current = new AudioContext({ sampleRate: 48000 });\n          console.log('[CoachSession] Created new AudioContext');\n        }\n        \n        if (audioContextRef.current.state === 'suspended') {\n          audioContextRef.current.resume();\n          console.log('[CoachSession] Resumed AudioContext');\n        }\n        \n        const analyser = audioContextRef.current.createAnalyser();\n        analyser.fftSize = 256;\n        const source = audioContextRef.current.createMediaElementSource(audioPlayerRef.current);\n        source.connect(analyser);\n        analyser.connect(audioContextRef.current.destination);\n        \n        analyserRef.current = analyser;\n        audioSourceCreatedRef.current = true;\n        console.log('[CoachSession] Audio analyzer setup complete');\n      } catch (error) {\n        console.error('[CoachSession] Error setting up audio analyzer:', error);\n      }\n    }\n    \n    audioPlayerRef.current.play()\n      .then(() => {\n        console.log('[CoachSession] Audio playing successfully');\n        setIsSpeaking(true);\n        setCurrentAnimation('talking');\n        console.log('[CoachSession] Animation state set to: talking');\n      })\n      .catch(e => {\n        console.error('[CoachSession] Error playing audio:', e);\n        isPlayingRef.current = false;\n        setIsSpeaking(false);\n        setCurrentAnimation('idle');\n        console.log('[CoachSession] Animation state set to: idle');\n        setTimeout(() => playNextAudioFromQueue(), 100);\n      });\n    \n    audioPlayerRef.current.onended = () => {\n      console.log('[CoachSession] Audio playback ended');\n      URL.revokeObjectURL(audioUrl);\n      isPlayingRef.current = false;\n      setIsSpeaking(false);\n      setCurrentAnimation('idle');\n      console.log('[CoachSession] Animation state set to: idle');\n      // Play next audio if available\n      setTimeout(() => playNextAudioFromQueue(), 100);\n    };\n  };\n\n  // Audio analysis for lip sync\n  useEffect(() => {\n    if (!isSpeaking || !analyserRef.current) {\n      setAudioData(new Uint8Array());\n      return;\n    }\n\n    console.log('[CoachSession] Starting audio analysis for lip sync');\n    const analyser = analyserRef.current;\n    const bufferLength = analyser.frequencyBinCount;\n    const dataArray = new Uint8Array(bufferLength);\n    let animationId: number;\n    let lastLogTime = 0;\n\n    const updateAudioData = () => {\n      analyser.getByteFrequencyData(dataArray);\n      setAudioData(new Uint8Array(dataArray)); // Create a copy to trigger re-render\n      \n      // Log audio levels periodically for debugging\n      const now = Date.now();\n      if (now - lastLogTime > 1000) {\n        const avgLevel = dataArray.reduce((sum, val) => sum + val, 0) / dataArray.length;\n        console.log('[CoachSession] Audio analysis - Avg level:', avgLevel.toFixed(2), 'Max:', Math.max(...dataArray));\n        lastLogTime = now;\n      }\n      \n      animationId = requestAnimationFrame(updateAudioData);\n    };\n\n    updateAudioData();\n\n    return () => {\n      if (animationId) {\n        cancelAnimationFrame(animationId);\n      }\n      console.log('[CoachSession] Stopping audio analysis for lip sync');\n      setAudioData(new Uint8Array()); // Clear audio data when not speaking\n    };\n  }, [isSpeaking]);\n\n  // Handle send message\n  const sendMessage = async (text: string) => {\n    if (!text.trim() || !isConnected) return;\n    \n    try {\n      if (humeVoiceServiceRef.current) {\n        await humeVoiceServiceRef.current.sendMessage(text);\n      }\n    } catch (err) {\n      console.error('Failed to send message:', err);\n    }\n  };\n\n  // Check for credentials on mount\n  useEffect(() => {\n    const credentials = getHumeCredentials();\n    if (!credentials.apiKey || !credentials.secretKey) {\n      setShowEmergencyCredentialsInput(true);\n      setError('Hume credentials not configured. Please use the emergency credentials form.');\n    }\n  }, []);\n\n  return (\n    <div className=\"coach-session\">\n      <MediaDebug />\n      <div className=\"coach-header\">\n        <h1>Coach Session: {coach?.name || 'Unknown Coach'}</h1>\n        <button onClick={() => navigate('/coaches')} className=\"back-button\">\n          Back to Coaches\n        </button>\n      </div>\n\n      <div className=\"session-container\">\n        {showEmergencyCredentialsInput && (\n          <EmergencyCredentialsInput />\n        )}\n        <div className=\"coach-avatar-scene\" style={{ \n          backgroundColor: '#1a1a1a',\n          backgroundImage: coach?.venue ? `url(/Venues/${coach.venue})` : 'none',\n          backgroundSize: 'cover',\n          backgroundPosition: 'center',\n          backgroundRepeat: 'no-repeat'\n        }}>\n          {isConnected && (\n            <Canvas camera={{ position: [0, 0.8, 3], fov: 35 }}>\n              <ambientLight intensity={0.8} />\n              <directionalLight position={[0, 1, 2]} intensity={1.2} />\n              <Suspense fallback={null}>\n                <PresenceAvatar\n                  avatarUrl={coach?.avatar || '/avatars/coach_grace.glb'}\n                  position={[0, -1.8, 0]}\n                  scale={1.3}\n                  animationName={currentAnimation}\n                  emotionalBlendshapes={emotionalBlendshapes}\n                  audioData={audioData}\n                />\n              </Suspense>\n            </Canvas>\n          )}\n          {!isConnected && coach && (\n            <div className=\"coach-preview\" style={{\n              display: 'flex',\n              flexDirection: 'column',\n              alignItems: 'center',\n              justifyContent: 'center',\n              height: '100%',\n              color: 'white',\n              textAlign: 'center',\n              padding: '2rem'\n            }}>\n              <h2>{coach.name}</h2>\n              <p>{coach.description}</p>\n              <p style={{ marginTop: '2rem', opacity: 0.8 }}>\n                Click \"Start Coach Session\" to begin\n              </p>\n            </div>\n          )}\n        </div>\n        \n        {/* Debug indicator for speaking state */}\n        {process.env.NODE_ENV === 'development' && (\n          <div style={{\n            position: 'absolute',\n            top: '10px',\n            right: '10px',\n            padding: '5px 10px',\n            backgroundColor: isSpeaking ? '#4CAF50' : '#666',\n            color: 'white',\n            borderRadius: '5px',\n            fontSize: '12px',\n            zIndex: 1000\n          }}>\n            {isSpeaking ? 'ðŸŽ¤ Speaking' : 'ðŸ”‡ Silent'}\n          </div>\n        )}\n\n        <div className=\"session-controls\">\n          {!isConnected ? (\n            <button \n              onClick={handleConnect}\n              disabled={!hasPermissions || loading}\n              className=\"control-button start-button\"\n            >\n              {loading ? 'Connecting...' : 'Start Coach Session'}\n            </button>\n          ) : (\n            <button \n              onClick={handleDisconnect}\n              className=\"control-button end-button\"\n            >\n              End Session (Stop Billing)\n            </button>\n          )}\n          <div className=\"connection-status\">\n            Status: {isConnected ? 'ðŸŸ¢ Connected (Using API Credits)' : 'âš« Disconnected'}\n          </div>\n        </div>\n      </div>\n\n      {/* PiP Avatar with face tracking */}\n      {hasPermissions && cameraStream && (\n        <UserAvatarPiP \n          avatarUrl=\"/avatars/user_avatar.glb\"\n          position=\"bottom-right\"\n          size=\"medium\"\n          trackingData={faceTrackingData}\n          enableOwnTracking={true}\n          cameraStream={cameraStream}\n        />\n      )}\n    </div>\n  );\n};\n\nexport default CoachSession;\n"],"names":["CoachSession","coachId","useParams","navigate","useNavigate","coach","getCoachById","isListening","setIsListening","getHumeCoachConfig","useState","currentEmotion","setCurrentEmotion","audioData","setAudioData","Uint8Array","coachMessage","setCoachMessage","userTranscript","setUserTranscript","loading","setLoading","error","setError","faceTrackingData","setFaceTrackingData","messageInput","setMessageInput","cameraStream","setCameraStream","hasPermissions","setHasPermissions","currentAnimation","setCurrentAnimation","emotionalBlendshapes","setEmotionalBlendshapes","isSpeaking","setIsSpeaking","isConnected","setIsConnected","messages","setMessages","showEmergencyCredentialsInput","setShowEmergencyCredentialsInput","humeVoiceServiceRef","useRef","audioContextRef","analyserRef","audioPlayerRef","Audio","audioQueueRef","isPlayingRef","audioSourceCreatedRef","useEffect","current","onended","console","log","setTimeout","playNextAudioFromQueue","state","close","async","stream","navigator","mediaDevices","getUserMedia","video","audio","getVideoTracks","forEach","track","addEventListener","getMediaPermissions","getTracks","stop","HybridVoiceService","onAudio","audioBlob","size","push","onMessage","message","_message$message","messageText","content","JSON","stringify","_message$models","_message$models$proso","trim","prev","role","models","prosody","scores","emotionsArray","Object","entries","map","_ref","name","score","charAt","toUpperCase","slice","blendshapes","mapEmotionsToBlendshapes","onAssistantEnd","onUserMessage","transcript","onError","initHybridVoiceService","length","shift","audioUrl","URL","createObjectURL","src","AudioContext","window","webkitAudioContext","sampleRate","resume","analyser","createAnalyser","fftSize","createMediaElementSource","connect","destination","play","then","catch","e","revokeObjectURL","bufferLength","frequencyBinCount","dataArray","animationId","lastLogTime","updateAudioData","getByteFrequencyData","now","Date","avgLevel","reduce","sum","val","toFixed","Math","max","requestAnimationFrame","cancelAnimationFrame","credentials","getHumeCredentials","apiKey","secretKey","_jsxs","className","children","_jsx","MediaDebug","onClick","EmergencyCredentialsInput","style","backgroundColor","backgroundImage","venue","concat","backgroundSize","backgroundPosition","backgroundRepeat","Canvas","camera","position","fov","intensity","Suspense","fallback","PresenceAvatar","avatarUrl","avatar","scale","animationName","display","flexDirection","alignItems","justifyContent","height","color","textAlign","padding","description","marginTop","opacity","process","disconnect","err","configId","humeConfigId","Error","disabled","UserAvatarPiP","trackingData","enableOwnTracking"],"sourceRoot":""}